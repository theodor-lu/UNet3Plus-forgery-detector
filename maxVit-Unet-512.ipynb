{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING CONFIGURATION\n",
      "============================================================\n",
      "Image Size: (512, 512)\n",
      "Batch Size: 2\n",
      "Model: MaxViT Base CBAM UNet (CBAM reduction=4)\n",
      "Skip Pretrained: NO\n",
      "Epochs: 30\n",
      "Learning Rate: 8e-05\n",
      "Optimizer: adam\n",
      "Segmentation Loss: Focal (0.5, alpha=0.25, gamma=2.0) + Dice (0.5)\n",
      "Patience: 99\n",
      "Train/Val Split: 0.9\n",
      "Curriculum Learning: OFF\n",
      "\n",
      "Augmentation Parameters:\n",
      "  Master Switch: ON\n",
      "  Spatial: Rotation=ON (±10°), HFlip=ON (p=0.5), VFlip=ON (p=0.5)\n",
      "  Color: ON (Brightness=±0.2, Contrast=±0.2, Saturation=±0.2)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - Adjust these parameters as needed\n",
    "# ============================================================================\n",
    "\n",
    "class Config:\n",
    "    # Dataset parameters\n",
    "    IMG_SIZE = (512, 512)  # Image dimensions (height, width)\n",
    "    TRAIN_VAL_SPLIT = 0.9  # Train/validation split ratio\n",
    "    \n",
    "    # DataLoader parameters\n",
    "    BATCH_SIZE = 2  # Batch size for training\n",
    "    NUM_WORKERS = 0  # Set to 0 for Windows, increase for Linux/Mac\n",
    "    PIN_MEMORY = True  # Set to True if using GPU\n",
    "    \n",
    "    # Model architecture parameters\n",
    "    # ResNet CBAM UNet uses pretrained ResNet50 as encoder\n",
    "    IN_CHANNELS = 3  # RGB input channels\n",
    "    OUT_CHANNELS = 1  # Binary segmentation output\n",
    "    CBAM_REDUCTION = 4  # Reduction factor for CBAM attention modules\n",
    "    SKIP_PRETRAINED = False  # If True, skip loading pretrained weights (train from scratch or use checkpoint only)\n",
    "    \n",
    "    # Training parameters\n",
    "    NUM_EPOCHS = 30\n",
    "    LEARNING_RATE =8e-5\n",
    "    OPTIMIZER = 'adam'  # 'adam' or 'sgd'\n",
    "    WEIGHT_DECAY = 0.0  # L2 regularization weight\n",
    "    USE_CURRICULUM_LEARNING = False  # Enable/disable curriculum learning (sorts masks by area, progressive training)\n",
    "    \n",
    "    # Loss function parameters\n",
    "    FOCAL_WEIGHT = 0.5  # Weight for Focal loss (segmentation)\n",
    "    DICE_WEIGHT = 0.5  # Weight for Dice loss (segmentation)\n",
    "    DICE_SMOOTH = 1e-6  # Smoothing factor for Dice loss (avoid division by zero)\n",
    "    FOCAL_ALPHA = 0.25  # Alpha parameter for Focal loss (class balancing)\n",
    "    FOCAL_GAMMA = 2.0  # Gamma parameter for Focal loss (focusing parameter)\n",
    "    \n",
    "    # Early stopping parameters\n",
    "    PATIENCE = 99  # Number of epochs to wait before early stopping\n",
    "    MIN_DELTA = 0.0  # Minimum change to qualify as improvement\n",
    "    \n",
    "    # Output directories\n",
    "    OUTPUT_DIR = 'outputs'  # Main output directory\n",
    "    VIZ_DIR = 'outputs/visualizations'  # Directory to save visualizations\n",
    "    CHECKPOINT_DIR = 'outputs/checkpoints'  # Directory to save model checkpoints\n",
    "    \n",
    "    # Visualization parameters\n",
    "    NUM_VIZ_IMAGES = 2  # Number of images to visualize per epoch\n",
    "    \n",
    "    # Model saving parameters\n",
    "    MODEL_SAVE_NAME = 'MaxVit-Unet-defacto-best.pth'  # Best model checkpoint name\n",
    "    MODEL_COMPLETE_NAME = 'MaxVit-Unet-defacto-complete.pth'  # Complete model save name\n",
    "    \n",
    "    # Dataset paths\n",
    "    IMAGE_FOLDER = 'archive/copymove_img/img'\n",
    "    DONOR_MASK_FOLDER = 'archive/copymove_annotations/donor_mask'\n",
    "    PROBE_MASK_FOLDER = 'archive/copymove_annotations/probe_mask'\n",
    "    \n",
    "    # Augmentation parameters\n",
    "    USE_AUGMENTATION = True  # Master switch: Enable/disable all data augmentation\n",
    "    \n",
    "    # Spatial augmentation switches (applied to both image and mask)\n",
    "    AUG_ENABLE_ROTATION = True  # Enable/disable rotation augmentation\n",
    "    AUG_ROTATION = 10  # Rotation angle in degrees (±) - only used if AUG_ENABLE_ROTATION=True\n",
    "    AUG_ENABLE_HFLIP = True  # Enable/disable horizontal flip augmentation\n",
    "    AUG_HFLIP = 0.5  # Probability of horizontal flip - only used if AUG_ENABLE_HFLIP=True\n",
    "    AUG_ENABLE_VFLIP = True  # Enable/disable vertical flip augmentation\n",
    "    AUG_VFLIP = 0.5  # Probability of vertical flip - only used if AUG_ENABLE_VFLIP=True\n",
    "    \n",
    "    # Color augmentation switches (applied to image only)\n",
    "    AUG_ENABLE_COLOR = True  # Enable/disable color augmentations (brightness, contrast, saturation)\n",
    "    AUG_BRIGHTNESS = 0.2  # Brightness adjustment range (±) - only used if AUG_ENABLE_COLOR=True\n",
    "    AUG_CONTRAST = 0.2  # Contrast adjustment range (±) - only used if AUG_ENABLE_COLOR=True\n",
    "    AUG_SATURATION = 0.2  # Saturation adjustment range (±) - only used if AUG_ENABLE_COLOR=True\n",
    "    \n",
    "    # Mask smoothing parameters\n",
    "    MASK_GAUSSIAN_BLUR_RADIUS = 1.0  # Gaussian blur radius for mask label smoothing (0.0 = disabled)\n",
    "\n",
    "# Create config instance\n",
    "config = Config()\n",
    "\n",
    "# Print configuration\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Image Size: {config.IMG_SIZE}\")\n",
    "print(f\"Batch Size: {config.BATCH_SIZE}\")\n",
    "print(f\"Model: MaxViT Base CBAM UNet (CBAM reduction={config.CBAM_REDUCTION})\")\n",
    "print(f\"Skip Pretrained: {'YES' if config.SKIP_PRETRAINED else 'NO'}\")\n",
    "print(f\"Epochs: {config.NUM_EPOCHS}\")\n",
    "print(f\"Learning Rate: {config.LEARNING_RATE}\")\n",
    "print(f\"Optimizer: {config.OPTIMIZER}\")\n",
    "print(f\"Segmentation Loss: Focal ({config.FOCAL_WEIGHT}, alpha={config.FOCAL_ALPHA}, gamma={config.FOCAL_GAMMA}) + Dice ({config.DICE_WEIGHT})\")\n",
    "print(f\"Patience: {config.PATIENCE}\")\n",
    "print(f\"Train/Val Split: {config.TRAIN_VAL_SPLIT}\")\n",
    "print(f\"Curriculum Learning: {'ON' if config.USE_CURRICULUM_LEARNING else 'OFF'}\")\n",
    "print()\n",
    "print(\"Augmentation Parameters:\")\n",
    "print(f\"  Master Switch: {'ON' if config.USE_AUGMENTATION else 'OFF'}\")\n",
    "if config.USE_AUGMENTATION:\n",
    "    print(f\"  Spatial: Rotation={'ON' if config.AUG_ENABLE_ROTATION else 'OFF'} (±{config.AUG_ROTATION}°), \"\n",
    "          f\"HFlip={'ON' if config.AUG_ENABLE_HFLIP else 'OFF'} (p={config.AUG_HFLIP}), \"\n",
    "          f\"VFlip={'ON' if config.AUG_ENABLE_VFLIP else 'OFF'} (p={config.AUG_VFLIP})\")\n",
    "    print(f\"  Color: {'ON' if config.AUG_ENABLE_COLOR else 'OFF'} \"\n",
    "          f\"(Brightness=±{config.AUG_BRIGHTNESS}, Contrast=±{config.AUG_CONTRAST}, Saturation=±{config.AUG_SATURATION})\")\n",
    "else:\n",
    "    print(\"  All augmentations disabled\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Pretrained weights already exist at: pretrained_models\\model.pth\n",
      "  Skipping download. Delete this file if you want to redownload.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DOWNLOAD AND SAVE PRETRAINED WEIGHTS\n",
    "# ============================================================================\n",
    "# This cell downloads the MaxViT pretrained weights and saves them locally\n",
    "# to avoid redownloading them each time you run the notebook.\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import timm\n",
    "\n",
    "# Create pretrained_models directory if it doesn't exist\n",
    "PRETRAINED_MODELS_DIR = 'pretrained_models'\n",
    "os.makedirs(PRETRAINED_MODELS_DIR, exist_ok=True)\n",
    "\n",
    "# Check if weights already exist\n",
    "weight_files = ['model.safetensors', 'pytorch_model.bin', 'model.pth']\n",
    "local_weights_path = None\n",
    "weights_exist = False\n",
    "\n",
    "for weight_file in weight_files:\n",
    "    weight_path = os.path.join(PRETRAINED_MODELS_DIR, weight_file)\n",
    "    if os.path.exists(weight_path):\n",
    "        local_weights_path = weight_path\n",
    "        weights_exist = True\n",
    "        print(f\"✓ Pretrained weights already exist at: {local_weights_path}\")\n",
    "        print(\"  Skipping download. Delete this file if you want to redownload.\")\n",
    "        break\n",
    "\n",
    "# Download and save weights if they don't exist\n",
    "if not weights_exist:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"DOWNLOADING PRETRAINED WEIGHTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Set environment variables for faster download\n",
    "    os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '1'\n",
    "    os.environ['HF_HUB_DOWNLOAD_TIMEOUT'] = '600'  # 10 minutes timeout\n",
    "    \n",
    "    try:\n",
    "        print(\"Downloading MaxViT Base pretrained weights from Hugging Face...\")\n",
    "        # Download the model with pretrained weights (num_classes=0 removes classifier head)\n",
    "        maxvit = timm.create_model(\n",
    "            'maxvit_base_tf_512.in21k_ft_in1k',\n",
    "            pretrained=True,\n",
    "            num_classes=0  # Remove classifier head\n",
    "        )\n",
    "        \n",
    "        # Save the state dict to pretrained_models folder\n",
    "        save_path = os.path.join(PRETRAINED_MODELS_DIR, 'model.pth')\n",
    "        torch.save(maxvit.state_dict(), save_path)\n",
    "        \n",
    "        print(f\"✓ Successfully downloaded and saved pretrained weights!\")\n",
    "        print(f\"  Saved to: {save_path}\")\n",
    "        print(f\"  File size: {os.path.getsize(save_path) / (1024**2):.2f} MB\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Warning: Failed to download with primary model name: {e}\")\n",
    "        print(\"Trying alternative model name...\")\n",
    "        try:\n",
    "            maxvit = timm.create_model(\n",
    "                'maxvit_base_tf_512.in21k_ft_in1k',\n",
    "                pretrained=True,\n",
    "                num_classes=0\n",
    "            )\n",
    "            \n",
    "            # Save the state dict\n",
    "            save_path = os.path.join(PRETRAINED_MODELS_DIR, 'model.pth')\n",
    "            torch.save(maxvit.state_dict(), save_path)\n",
    "            \n",
    "            print(f\"✓ Successfully downloaded and saved pretrained weights!\")\n",
    "            print(f\"  Saved to: {save_path}\")\n",
    "            print(f\"  File size: {os.path.getsize(save_path) / (1024**2):.2f} MB\")\n",
    "            \n",
    "        except Exception as e2:\n",
    "            print(f\"✗ Error: Failed to download pretrained weights: {e2}\")\n",
    "            print(\"  The model will be created without pretrained weights.\")\n",
    "            print(\"  You can train from scratch or manually download the weights.\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 9439,
     "status": "ok",
     "timestamp": 1751816052150,
     "user": {
      "displayName": "JAYESH SHARMA",
      "userId": "10181368842352240411"
     },
     "user_tz": -330
    },
    "id": "b645LenOP6Ni",
    "outputId": "f410e9be-e14b-4a3b-8291-de9cfaedf6df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Found checkpoint: outputs/checkpoints\\MaxVit-Unet-defacto-best.pth\n",
      "  Loading from checkpoint instead of pretrained weights...\n",
      "  Checkpoint file: outputs/checkpoints\\MaxVit-Unet-defacto-best.pth\n",
      "Creating MaxViT model without pretrained weights (skip_pretrained=True)...\n",
      "Downloading MaxViT pretrained weights from Hugging Face...\n",
      "✓ Successfully downloaded and loaded pretrained weights!\n",
      "⚠ Warning: Failed to load pretrained weights: cannot access local variable 'PRETRAINED_MODELS_DIR' where it is not associated with a value\n",
      "Trying alternative model name...\n",
      "✓ Successfully loaded with alternative model name!\n",
      "⚠ Warning: Failed to load pretrained weights: cannot access local variable 'PRETRAINED_MODELS_DIR' where it is not associated with a value\n",
      "Creating model without pretrained weights. You can train from scratch.\n",
      "  Tip: Run the 'Download and Save Pretrained Weights' cell first to download weights.\n",
      "✓ Successfully loaded model from checkpoint!\n",
      "  Model weights loaded from: outputs/checkpoints\\MaxVit-Unet-defacto-best.pth\n",
      "Model created on device: cuda\n",
      "Total parameters: 127,110,609\n",
      "MaxViT_CBAM_UNet(\n",
      "  (encoder1): Identity()\n",
      "  (stem): Stem(\n",
      "    (conv1): Conv2dSame(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (norm1): BatchNormAct2d(\n",
      "      64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "      (drop): Identity()\n",
      "      (act): GELUTanh()\n",
      "    )\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (stage1): MaxxVitStage(\n",
      "    (blocks): Sequential(\n",
      "      (0): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Downsample2d(\n",
      "            (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
      "            (expand): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2dSame(384, 384, kernel_size=(3, 3), stride=(2, 2), groups=384, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stage2): MaxxVitStage(\n",
      "    (blocks): Sequential(\n",
      "      (0): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Downsample2d(\n",
      "            (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
      "            (expand): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(96, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2dSame(768, 768, kernel_size=(3, 3), stride=(2, 2), groups=768, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (5): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stage3): MaxxVitStage(\n",
      "    (blocks): Sequential(\n",
      "      (0): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Downsample2d(\n",
      "            (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
      "            (expand): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(192, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2dSame(1536, 1536, kernel_size=(3, 3), stride=(2, 2), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (5): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (6): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (7): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (8): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (9): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (10): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (11): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (12): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (13): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (stage4): MaxxVitStage(\n",
      "    (blocks): Sequential(\n",
      "      (0): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Downsample2d(\n",
      "            (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
      "            (expand): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2dSame(3072, 3072, kernel_size=(3, 3), stride=(2, 2), groups=3072, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (encoder2): Sequential(\n",
      "    (0): Stem(\n",
      "      (conv1): Conv2dSame(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "      (norm1): BatchNormAct2d(\n",
      "        64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (drop): Identity()\n",
      "        (act): GELUTanh()\n",
      "      )\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): MaxxVitStage(\n",
      "      (blocks): Sequential(\n",
      "        (0): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Downsample2d(\n",
      "              (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
      "              (expand): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            )\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2dSame(384, 384, kernel_size=(3, 3), stride=(2, 2), groups=384, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (1): MaxxVitBlock(\n",
      "          (conv): MbConvBlock(\n",
      "            (shortcut): Identity()\n",
      "            (pre_norm): BatchNormAct2d(\n",
      "              96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): Identity()\n",
      "            )\n",
      "            (down): Identity()\n",
      "            (conv1_1x1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (norm1): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (conv2_kxk): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "            (norm2): BatchNormAct2d(\n",
      "              384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "              (drop): Identity()\n",
      "              (act): GELUTanh()\n",
      "            )\n",
      "            (se): SEModule(\n",
      "              (fc1): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (bn): Identity()\n",
      "              (act): SiLU(inplace=True)\n",
      "              (fc2): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (gate): Sigmoid()\n",
      "            )\n",
      "            (conv3_1x1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (drop_path): Identity()\n",
      "          )\n",
      "          (attn_block): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (attn_grid): PartitionAttentionCl(\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): AttentionCl(\n",
      "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "              (rel_pos): RelPosBiasTf()\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): Identity()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELUTanh()\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): Identity()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (se2): CBAM(\n",
      "    (channel_attention): ChannelAttention(\n",
      "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "      (fc): Sequential(\n",
      "        (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "    (spatial_attention): SpatialAttention(\n",
      "      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (encoder3): MaxxVitStage(\n",
      "    (blocks): Sequential(\n",
      "      (0): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Downsample2d(\n",
      "            (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
      "            (expand): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(96, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2dSame(768, 768, kernel_size=(3, 3), stride=(2, 2), groups=768, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (5): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (se3): CBAM(\n",
      "    (channel_attention): ChannelAttention(\n",
      "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "      (fc): Sequential(\n",
      "        (0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "    (spatial_attention): SpatialAttention(\n",
      "      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (encoder4): MaxxVitStage(\n",
      "    (blocks): Sequential(\n",
      "      (0): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Downsample2d(\n",
      "            (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
      "            (expand): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(192, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2dSame(1536, 1536, kernel_size=(3, 3), stride=(2, 2), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (5): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (6): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (7): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (8): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (9): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (10): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (11): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (12): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (13): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(1536, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(96, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (se4): CBAM(\n",
      "    (channel_attention): ChannelAttention(\n",
      "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "      (fc): Sequential(\n",
      "        (0): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "    (spatial_attention): SpatialAttention(\n",
      "      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (encoder5): MaxxVitStage(\n",
      "    (blocks): Sequential(\n",
      "      (0): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Downsample2d(\n",
      "            (pool): AvgPool2dSame(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
      "            (expand): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(384, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2dSame(3072, 3072, kernel_size=(3, 3), stride=(2, 2), groups=3072, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): MaxxVitBlock(\n",
      "        (conv): MbConvBlock(\n",
      "          (shortcut): Identity()\n",
      "          (pre_norm): BatchNormAct2d(\n",
      "            768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): Identity()\n",
      "          )\n",
      "          (down): Identity()\n",
      "          (conv1_1x1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (norm1): BatchNormAct2d(\n",
      "            3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (conv2_kxk): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
      "          (norm2): BatchNormAct2d(\n",
      "            3072, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (drop): Identity()\n",
      "            (act): GELUTanh()\n",
      "          )\n",
      "          (se): SEModule(\n",
      "            (fc1): Conv2d(3072, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (bn): Identity()\n",
      "            (act): SiLU(inplace=True)\n",
      "            (fc2): Conv2d(192, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (gate): Sigmoid()\n",
      "          )\n",
      "          (conv3_1x1): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (attn_block): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (attn_grid): PartitionAttentionCl(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): AttentionCl(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (rel_pos): RelPosBiasTf()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELUTanh()\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (bottleneck): Identity()\n",
      "  (upconv5): ConvTranspose2d(768, 384, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (decoder5): Coder(\n",
      "    (conv1): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (upconv4): ConvTranspose2d(384, 192, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (decoder4): Coder(\n",
      "    (conv1): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (upconv3): ConvTranspose2d(192, 96, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (decoder3): Coder(\n",
      "    (conv1): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (upconv2): ConvTranspose2d(96, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (se2_stem): CBAM(\n",
      "    (channel_attention): ChannelAttention(\n",
      "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "      (fc): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "    (spatial_attention): SpatialAttention(\n",
      "      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (decoder2): Coder(\n",
      "    (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (upconv1): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (se1): CBAM(\n",
      "    (channel_attention): ChannelAttention(\n",
      "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "      (fc): Sequential(\n",
      "        (0): Conv2d(67, 67, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): ReLU()\n",
      "        (2): Conv2d(67, 67, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "    (spatial_attention): SpatialAttention(\n",
      "      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (decoder1): Coder(\n",
      "    (conv1): Conv2d(67, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"Channel Attention Module (SE-Net style)\"\"\"\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        # Use full channels without reduction\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, in_channels, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (B, C, H, W)\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    \"\"\"Spatial Attention Module\"\"\"\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (B, C, H, W)\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        out = torch.cat([avg_out, max_out], dim=1)\n",
    "        out = self.conv(out)\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    \"\"\"Convolutional Block Attention Module (Channel + Spatial)\"\"\"\n",
    "    def __init__(self, in_channels, reduction=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(in_channels, reduction)\n",
    "        self.spatial_attention = SpatialAttention(kernel_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Apply channel attention first\n",
    "        x = x * self.channel_attention(x)\n",
    "        # Then apply spatial attention\n",
    "        x = x * self.spatial_attention(x)\n",
    "        return x\n",
    "\n",
    "class Coder(nn.Module):\n",
    "    \"\"\"Decoder block for UNet - processes concatenated features\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Coder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "class MaxViT_CBAM_UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, r=16, skip_pretrained=False):\n",
    "        super(MaxViT_CBAM_UNet, self).__init__()\n",
    "        \n",
    "        import os\n",
    "        \n",
    "        # Initialize weights_loaded to avoid UnboundLocalError\n",
    "        weights_loaded = False\n",
    "        \n",
    "        # If skip_pretrained is True, create model without pretrained weights\n",
    "        if skip_pretrained:\n",
    "            print(\"Creating MaxViT model without pretrained weights (skip_pretrained=True)...\")\n",
    "            maxvit = timm.create_model('maxvit_base_tf_512.in21k_ft_in1k', pretrained=False, num_classes=0)\n",
    "        else:\n",
    "            # Load pretrained MaxViT Base from timm (512x512 pretrained)\n",
    "            # Note: Correct model name is 'maxvit_base_tf_512.in21k_ft_in1k' (tf = TensorFlow weights)\n",
    "            \n",
    "            # Load MaxViT Base model (embeddings only, no classifier head)\n",
    "            # Using num_classes=0 removes the classifier nn.Linear layer\n",
    "            \n",
    "            PRETRAINED_MODELS_DIR = 'pretrained_models'\n",
    "            os.makedirs(PRETRAINED_MODELS_DIR, exist_ok=True)\n",
    "            \n",
    "            # Check for downloaded weights in local folder\n",
    "            weight_files = ['model.safetensors', 'pytorch_model.bin', 'model.pth']\n",
    "            local_weights_path = None\n",
    "            \n",
    "            for weight_file in weight_files:\n",
    "                weight_path = os.path.join(PRETRAINED_MODELS_DIR, weight_file)\n",
    "                if os.path.exists(weight_path):\n",
    "                    local_weights_path = weight_path\n",
    "                    break\n",
    "            \n",
    "            # Try loading from local folder first\n",
    "            if local_weights_path:\n",
    "                try:\n",
    "                    print(f\"Loading MaxViT from local weights: {local_weights_path}\")\n",
    "                    # Create model without classifier head (num_classes=0)\n",
    "                    maxvit = timm.create_model(\n",
    "                        'maxvit_base_tf_512.in21k_ft_in1k',\n",
    "                        pretrained=False,\n",
    "                        num_classes=0  # Remove classifier head\n",
    "                    )\n",
    "                    \n",
    "                    # Load the weights\n",
    "                    if local_weights_path.endswith('.safetensors'):\n",
    "                        from safetensors.torch import load_file\n",
    "                        state_dict = load_file(local_weights_path)\n",
    "                    else:\n",
    "                        state_dict = torch.load(local_weights_path, map_location='cpu')\n",
    "                    \n",
    "                    # Filter state dict to match model architecture (remove classifier head keys)\n",
    "                    model_dict = maxvit.state_dict()\n",
    "                    filtered_dict = {}\n",
    "                    for k, v in state_dict.items():\n",
    "                        # Skip classifier head keys (head.* or classifier.*)\n",
    "                        if 'head.' in k or 'classifier.' in k:\n",
    "                            continue\n",
    "                        if k in model_dict and v.shape == model_dict[k].shape:\n",
    "                            filtered_dict[k] = v\n",
    "                    \n",
    "                    missing_keys, unexpected_keys = maxvit.load_state_dict(filtered_dict, strict=False)\n",
    "                    if missing_keys:\n",
    "                        print(f\"  Note: {len(missing_keys)} keys not loaded\")\n",
    "                    if unexpected_keys:\n",
    "                        print(f\"  Note: {len(unexpected_keys)} unexpected keys ignored (including classifier head)\")\n",
    "                    \n",
    "                    weights_loaded = True\n",
    "                    print(\"✓ Successfully loaded pretrained weights from local folder!\")\n",
    "                    print(\"  Skipping download - using cached weights.\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"⚠ Failed to load from local folder: {e}\")\n",
    "                    print(\"Falling back to automatic download...\")\n",
    "                    weights_loaded = False\n",
    "        \n",
    "        # If local loading failed, try automatic download (and save for future use)\n",
    "        if not weights_loaded:\n",
    "            os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '1'\n",
    "            os.environ['HF_HUB_DOWNLOAD_TIMEOUT'] = '600'  # 10 minutes timeout\n",
    "            \n",
    "            try:\n",
    "                print(\"Downloading MaxViT pretrained weights from Hugging Face...\")\n",
    "                # Use num_classes=0 to get embeddings only (no classifier head)\n",
    "                maxvit = timm.create_model(\n",
    "                    'maxvit_base_tf_512.in21k_ft_in1k',\n",
    "                    pretrained=True,\n",
    "                    num_classes=0  # Remove classifier nn.Linear\n",
    "                )\n",
    "                weights_loaded = True\n",
    "                print(\"✓ Successfully downloaded and loaded pretrained weights!\")\n",
    "                \n",
    "                # Save the weights to pretrained_models folder for future use\n",
    "                save_path = os.path.join(PRETRAINED_MODELS_DIR, 'model.pth')\n",
    "                torch.save(maxvit.state_dict(), save_path)\n",
    "                print(f\"✓ Saved weights to {save_path} for future use\")\n",
    "                print(f\"  File size: {os.path.getsize(save_path) / (1024**2):.2f} MB\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"⚠ Warning: Failed to load pretrained weights: {e}\")\n",
    "                print(\"Trying alternative model name...\")\n",
    "                try:\n",
    "                    maxvit = timm.create_model(\n",
    "                        'maxvit_base_tf_512.in21k_ft_in1k',\n",
    "                        pretrained=True,\n",
    "                        num_classes=0\n",
    "                    )\n",
    "                    weights_loaded = True\n",
    "                    print(\"✓ Successfully loaded with alternative model name!\")\n",
    "                    \n",
    "                    # Save the weights to pretrained_models folder for future use\n",
    "                    save_path = os.path.join(PRETRAINED_MODELS_DIR, 'model.pth')\n",
    "                    torch.save(maxvit.state_dict(), save_path)\n",
    "                    print(f\"✓ Saved weights to {save_path} for future use\")\n",
    "                    print(f\"  File size: {os.path.getsize(save_path) / (1024**2):.2f} MB\")\n",
    "                    \n",
    "                except Exception as e2:\n",
    "                    print(f\"⚠ Warning: Failed to load pretrained weights: {e2}\")\n",
    "                    print(\"Creating model without pretrained weights. You can train from scratch.\")\n",
    "                    print(\"  Tip: Run the 'Download and Save Pretrained Weights' cell first to download weights.\")\n",
    "                    maxvit = timm.create_model('maxvit_base_tf_512.in21k_ft_in1k', pretrained=False, num_classes=0)\n",
    "                    weights_loaded = False\n",
    "        \n",
    "        # MaxViT Base feature dimensions (for 512x512 input):\n",
    "        # Stem: 64 channels, H/2 x W/2 (256x256)\n",
    "        # Stage 1: 96 channels, H/4 x W/4 (128x128)\n",
    "        # Stage 2: 192 channels, H/8 x W/8 (64x64)\n",
    "        # Stage 3: 384 channels, H/16 x W/16 (32x32)\n",
    "        # Stage 4: 768 channels, H/32 x W/32 (16x16)\n",
    "        \n",
    "        # Extract encoder stages from MaxViT\n",
    "        # Access the internal structure of MaxViT\n",
    "        self.encoder1 = nn.Identity()  # Input: (B, 3, H, W)\n",
    "        \n",
    "        # Get the stem and stages from MaxViT\n",
    "        # MaxViT structure: stem -> stages[0] -> stages[1] -> stages[2] -> stages[3]\n",
    "        self.stem = maxvit.stem  # Stem: (B, 3, H, W) -> (B, 64, H/2, W/2)\n",
    "        self.stage1 = maxvit.stages[0]  # Stage 1: (B, 64, H/2, W/2) -> (B, 96, H/4, W/4)\n",
    "        self.stage2 = maxvit.stages[1]  # Stage 2: (B, 96, H/4, W/4) -> (B, 192, H/8, W/8)\n",
    "        self.stage3 = maxvit.stages[2]  # Stage 3: (B, 192, H/8, W/8) -> (B, 384, H/16, W/16)\n",
    "        self.stage4 = maxvit.stages[3]  # Stage 4: (B, 384, H/16, W/16) -> (B, 768, H/32, W/32)\n",
    "        \n",
    "        # Encoder blocks\n",
    "        # We'll use stem output separately for skip connection\n",
    "        self.encoder2 = nn.Sequential(self.stem, self.stage1)  # Out: (B, 96, H/4, W/4)\n",
    "        self.se2 = CBAM(96 * 2, r)  # Skip connection: decoder + encoder2\n",
    "        \n",
    "        self.encoder3 = self.stage2  # Out: (B, 192, H/8, W/8)\n",
    "        self.se3 = CBAM(192 * 2, r)\n",
    "        \n",
    "        self.encoder4 = self.stage3  # Out: (B, 384, H/16, W/16)\n",
    "        self.se4 = CBAM(384 * 2, r)\n",
    "        \n",
    "        self.encoder5 = self.stage4  # Out: (B, 768, H/32, W/32)\n",
    "        # Note: se5 not needed since we skip from e4, not e5\n",
    "        \n",
    "        # Bottleneck (no additional layer needed, stage4 is the bottleneck)\n",
    "        self.bottleneck = nn.Identity()  # (B, 768, H/32, W/32)\n",
    "\n",
    "        # Decoder path - channels must match encoder outputs\n",
    "        self.upconv5 = nn.ConvTranspose2d(768, 384, kernel_size=2, stride=2)  # (B, 384, H/16, W/16)\n",
    "        self.decoder5 = Coder(384 * 2, 384)  # Skip: 384 (decoder) + 384 (encoder4)\n",
    "        \n",
    "        self.upconv4 = nn.ConvTranspose2d(384, 192, kernel_size=2, stride=2)  # (B, 192, H/8, W/8)\n",
    "        self.decoder4 = Coder(192 * 2, 192)  # Skip: 192 (decoder) + 192 (encoder3)\n",
    "        \n",
    "        self.upconv3 = nn.ConvTranspose2d(192, 96, kernel_size=2, stride=2)  # (B, 96, H/4, W/4)\n",
    "        self.decoder3 = Coder(96 * 2, 96)  # Skip: 96 (decoder) + 96 (encoder2)\n",
    "        \n",
    "        # For the final upsampling, we need to go from H/4 to H/2, then H/2 to H\n",
    "        # Stage 1 output is at H/4, so we need one more upsampling step\n",
    "        self.upconv2 = nn.ConvTranspose2d(96, 64, kernel_size=2, stride=2)  # (B, 64, H/2, W/2)\n",
    "        # We'll use stem output (64 channels at H/2) for skip connection\n",
    "        self.se2_stem = CBAM(64 * 2, r)  # Skip: 64 (decoder) + 64 (stem)\n",
    "        self.decoder2 = Coder(64 * 2, 64)\n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2)  # (B, 64, H, W)\n",
    "        self.se1 = CBAM(64 + 3, r)  # Skip: 64 (decoder) + 3 (input)\n",
    "        self.decoder1 = Coder(64 + 3, 64)\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=64, out_channels=out_channels, kernel_size=1)\n",
    "        \n",
    "        self.training_losses = []\n",
    "        self.eval_losses = []\n",
    "        self.training_iou = []\n",
    "        self.eval_iou = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder path\n",
    "        e1 = self.encoder1(x)  # (B, 3, H, W) - original input\n",
    "        \n",
    "        # Get stem output for skip connection\n",
    "        stem_out = self.stem(e1)  # (B, 64, H/2, W/2)\n",
    "        \n",
    "        # Encoder stages\n",
    "        e2 = self.encoder2(e1)  # (B, 96, H/4, W/4) - stem + stage1\n",
    "        e3 = self.encoder3(e2)  # (B, 192, H/8, W/8) - stage2\n",
    "        e4 = self.encoder4(e3)  # (B, 384, H/16, W/16) - stage3\n",
    "        e5 = self.encoder5(e4)  # (B, 768, H/32, W/32) - stage4\n",
    "        \n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(e5)  # (B, 768, H/32, W/32)\n",
    "        \n",
    "        # Decoder path with skip connections and CBAM\n",
    "        d5 = self.upconv5(bottleneck)  # (B, 384, H/16, W/16)\n",
    "        d5 = torch.cat([d5, e4], dim=1)  # (B, 384*2, H/16, W/16)\n",
    "        d5 = self.se4(d5)  # Apply CBAM\n",
    "        d5 = self.decoder5(d5)  # (B, 384, H/16, W/16)\n",
    "        \n",
    "        d4 = self.upconv4(d5)  # (B, 192, H/8, W/8)\n",
    "        d4 = torch.cat([d4, e3], dim=1)  # (B, 192*2, H/8, W/8)\n",
    "        d4 = self.se3(d4)  # Apply CBAM\n",
    "        d4 = self.decoder4(d4)  # (B, 192, H/8, W/8)\n",
    "        \n",
    "        d3 = self.upconv3(d4)  # (B, 96, H/4, W/4)\n",
    "        d3 = torch.cat([d3, e2], dim=1)  # (B, 96*2, H/4, W/4)\n",
    "        d3 = self.se2(d3)  # Apply CBAM\n",
    "        d3 = self.decoder3(d3)  # (B, 96, H/4, W/4)\n",
    "        \n",
    "        d2 = self.upconv2(d3)  # (B, 64, H/2, W/2)\n",
    "        d2 = torch.cat([d2, stem_out], dim=1)  # (B, 64*2, H/2, W/2)\n",
    "        d2 = self.se2_stem(d2)  # Apply CBAM\n",
    "        d2 = self.decoder2(d2)  # (B, 64, H/2, W/2)\n",
    "        \n",
    "        d1 = self.upconv1(d2)  # (B, 64, H, W)\n",
    "        d1 = torch.cat([d1, e1], dim=1)  # (B, 64+3, H, W)\n",
    "        d1 = self.se1(d1)  # Apply CBAM\n",
    "        d1 = self.decoder1(d1)  # (B, 64, H, W)\n",
    "        \n",
    "        # Output layer\n",
    "        output = self.conv(d1)  # (B, 1, H, W) - logits\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Check for existing checkpoint before creating model\n",
    "checkpoint_dir = config.CHECKPOINT_DIR\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Primary checkpoint to use (from config)\n",
    "primary_checkpoint = os.path.join(checkpoint_dir, config.MODEL_SAVE_NAME)\n",
    "\n",
    "# Fallback checkpoints (for backward compatibility with old names)\n",
    "fallback_checkpoint_path_old = os.path.join(checkpoint_dir, 'unet_comofod_best.pth')\n",
    "complete_checkpoint_path = os.path.join(checkpoint_dir, config.MODEL_COMPLETE_NAME)\n",
    "complete_checkpoint_path_pt = os.path.join(checkpoint_dir, config.MODEL_COMPLETE_NAME.replace('.pth', '.pt'))\n",
    "\n",
    "checkpoint_found = False\n",
    "checkpoint_to_load = None\n",
    "\n",
    "# Check for primary checkpoint first (from config)\n",
    "if os.path.exists(primary_checkpoint):\n",
    "    checkpoint_to_load = primary_checkpoint\n",
    "    checkpoint_found = True\n",
    "    print(f\"✓ Found checkpoint: {primary_checkpoint}\")\n",
    "# Check for old checkpoint name (fallback for backward compatibility)\n",
    "elif os.path.exists(fallback_checkpoint_path_old):\n",
    "    checkpoint_to_load = fallback_checkpoint_path_old\n",
    "    checkpoint_found = True\n",
    "    print(f\"✓ Found checkpoint (old name): {fallback_checkpoint_path_old}\")\n",
    "# Check for complete checkpoint (.pth) (fallback)\n",
    "elif os.path.exists(complete_checkpoint_path):\n",
    "    checkpoint_to_load = complete_checkpoint_path\n",
    "    checkpoint_found = True\n",
    "    print(f\"✓ Found checkpoint: {complete_checkpoint_path}\")\n",
    "# Check for complete checkpoint (.pt) (fallback)\n",
    "elif os.path.exists(complete_checkpoint_path_pt):\n",
    "    checkpoint_to_load = complete_checkpoint_path_pt\n",
    "    checkpoint_found = True\n",
    "    print(f\"✓ Found checkpoint: {complete_checkpoint_path_pt}\")\n",
    "\n",
    "if checkpoint_found:\n",
    "    print(f\"  Loading from checkpoint instead of pretrained weights...\")\n",
    "    print(f\"  Checkpoint file: {checkpoint_to_load}\")\n",
    "\n",
    "# Determine if we should skip pretrained weights\n",
    "# Skip if: config option is True OR checkpoint is found (checkpoint will overwrite pretrained anyway)\n",
    "skip_pretrained = config.SKIP_PRETRAINED or checkpoint_found\n",
    "\n",
    "if config.SKIP_PRETRAINED and not checkpoint_found:\n",
    "    print(f\"  Skipping pretrained weights (SKIP_PRETRAINED=True). Training from scratch or using checkpoint only.\")\n",
    "\n",
    "# Create model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Pass skip_pretrained flag to model initialization\n",
    "model = MaxViT_CBAM_UNet(\n",
    "    in_channels=config.IN_CHANNELS, \n",
    "    out_channels=config.OUT_CHANNELS,\n",
    "    r=config.CBAM_REDUCTION,\n",
    "    skip_pretrained=skip_pretrained\n",
    ").to(device)\n",
    "\n",
    "# Load checkpoint if found (this will overwrite pretrained weights)\n",
    "if checkpoint_found:\n",
    "    try:\n",
    "        if checkpoint_to_load.endswith('.pt'):\n",
    "            # Complete checkpoint format\n",
    "            checkpoint = torch.load(checkpoint_to_load, map_location=device)\n",
    "            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                print(f\"✓ Successfully loaded model from complete checkpoint!\")\n",
    "                if 'val_loss' in checkpoint:\n",
    "                    print(f\"  Checkpoint validation loss: {checkpoint['val_loss']:.4f}\")\n",
    "                if 'epoch' in checkpoint:\n",
    "                    print(f\"  Checkpoint epoch: {checkpoint['epoch']}\")\n",
    "            else:\n",
    "                # Treat as state dict\n",
    "                model.load_state_dict(checkpoint)\n",
    "                print(f\"✓ Successfully loaded model from checkpoint!\")\n",
    "        else:\n",
    "            # State dict format\n",
    "            model.load_state_dict(torch.load(checkpoint_to_load, map_location=device))\n",
    "            print(f\"✓ Successfully loaded model from checkpoint!\")\n",
    "        print(f\"  Model weights loaded from: {checkpoint_to_load}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Warning: Failed to load checkpoint: {e}\")\n",
    "        if config.SKIP_PRETRAINED:\n",
    "            print(f\"  Continuing without pretrained weights (SKIP_PRETRAINED=True).\")\n",
    "        else:\n",
    "            print(f\"  Continuing with pretrained weights instead...\")\n",
    "else:\n",
    "    if config.SKIP_PRETRAINED:\n",
    "        print(f\"No checkpoint found. Training from scratch (SKIP_PRETRAINED=True).\")\n",
    "    else:\n",
    "        print(f\"No checkpoint found. Using pretrained weights from MaxViT encoder.\")\n",
    "\n",
    "print(f\"Model created on device: {device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1751816057043,
     "user": {
      "displayName": "JAYESH SHARMA",
      "userId": "10181368842352240411"
     },
     "user_tz": -330
    },
    "id": "4r4rl96VQSfh",
    "outputId": "dd80a34c-d22f-4309-9dd1-d8956068fc0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Augmentation Configuration:\n",
      "  Master Switch: ON\n",
      "  Spatial Augmentations:\n",
      "    Rotation: ON (angle: ±10°)\n",
      "    Horizontal Flip: ON (prob: 0.5)\n",
      "    Vertical Flip: ON (prob: 0.5)\n",
      "  Color Augmentations: ON\n",
      "    Brightness: ±0.2\n",
      "    Contrast: ±0.2\n",
      "    Saturation: ±0.2\n",
      "Total images: 10523\n",
      "Note: All images in this dataset are forged (copymove forgeries)\n",
      "\n",
      "Sample shape - Image: torch.Size([3, 512, 512]), Mask: torch.Size([1, 512, 512]), Class: 1.0\n",
      "Image dtype: torch.float32, Mask dtype: torch.float32, Class dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "import os\n",
    "\n",
    "class JointTransform:\n",
    "    \"\"\"Apply the same spatial transformations to both image and mask\"\"\"\n",
    "    def __init__(self, rotation=15, hflip_prob=0.5, vflip_prob=0.0, \n",
    "                 enable_rotation=True, enable_hflip=True, enable_vflip=True):\n",
    "        self.rotation = rotation if enable_rotation else 0\n",
    "        self.hflip_prob = hflip_prob if enable_hflip else 0.0\n",
    "        self.vflip_prob = vflip_prob if enable_vflip else 0.0\n",
    "    \n",
    "    def __call__(self, img, mask):\n",
    "        # Random rotation\n",
    "        if self.rotation > 0:\n",
    "            angle = random.uniform(-self.rotation, self.rotation)\n",
    "            img = TF.rotate(img, angle, interpolation=TF.InterpolationMode.BILINEAR, fill=0)\n",
    "            mask = TF.rotate(mask, angle, interpolation=TF.InterpolationMode.NEAREST, fill=0)\n",
    "        \n",
    "        # Random horizontal flip\n",
    "        if self.hflip_prob > 0 and random.random() < self.hflip_prob:\n",
    "            img = TF.hflip(img)\n",
    "            mask = TF.hflip(mask)\n",
    "        \n",
    "        # Random vertical flip\n",
    "        if self.vflip_prob > 0 and random.random() < self.vflip_prob:\n",
    "            img = TF.vflip(img)\n",
    "            mask = TF.vflip(mask)\n",
    "        \n",
    "        return img, mask\n",
    "\n",
    "class ImageMaskDataset(Dataset):\n",
    "    def __init__(self, image_folder, donor_mask_folder, probe_mask_folder, img_size=(512, 512), transform=None, joint_transform=None, mask_blur_radius=0.0):\n",
    "        \"\"\"\n",
    "        Dataset for copymove forgery detection.\n",
    "        \n",
    "        Args:\n",
    "            image_folder: Path to folder containing images (.tif files)\n",
    "            donor_mask_folder: Path to folder containing donor masks (.tif files)\n",
    "            probe_mask_folder: Path to folder containing probe masks (.jpg files)\n",
    "            img_size: Target size for resizing images and masks (height, width)\n",
    "            transform: Image-only transforms (brightness, contrast, etc.)\n",
    "            joint_transform: Spatial transforms applied to both image and mask\n",
    "            mask_blur_radius: Gaussian blur radius for mask label smoothing (0.0 = disabled)\n",
    "        \"\"\"\n",
    "        # Get all image files and sort them\n",
    "        self.image_paths = sorted([\n",
    "            os.path.join(image_folder, f) \n",
    "            for f in os.listdir(image_folder) \n",
    "            if f.endswith('.tif')\n",
    "        ])\n",
    "        \n",
    "        # Build corresponding mask paths\n",
    "        self.donor_mask_paths = []\n",
    "        self.probe_mask_paths = []\n",
    "        \n",
    "        for img_path in self.image_paths:\n",
    "            filename = os.path.basename(img_path)\n",
    "            # Donor mask has same filename with .tif extension\n",
    "            donor_mask_path = os.path.join(donor_mask_folder, filename)\n",
    "            # Probe mask has same base name but .jpg extension\n",
    "            probe_mask_filename = os.path.splitext(filename)[0] + '.jpg'\n",
    "            probe_mask_path = os.path.join(probe_mask_folder, probe_mask_filename)\n",
    "            \n",
    "            self.donor_mask_paths.append(donor_mask_path)\n",
    "            self.probe_mask_paths.append(probe_mask_path)\n",
    "        \n",
    "        self.img_size = img_size\n",
    "        self.transform = transform  # For image-only transforms (brightness, contrast, etc.)\n",
    "        self.joint_transform = joint_transform  # For spatial transforms (rotation, flip)\n",
    "        self.mask_blur_radius = mask_blur_radius  # Gaussian blur radius for mask smoothing\n",
    "    \n",
    "    def _apply_mask_blur(self, mask):\n",
    "        \"\"\"Apply Gaussian blur to mask if blur radius > 0\"\"\"\n",
    "        if self.mask_blur_radius > 0:\n",
    "            # Use cv2.GaussianBlur for efficient blurring\n",
    "            # kernel_size must be odd, calculate from sigma\n",
    "            # sigma = blur_radius, kernel_size = 2 * ceil(3*sigma) + 1\n",
    "            import math\n",
    "            kernel_size = int(2 * math.ceil(3 * self.mask_blur_radius) + 1)\n",
    "            # Ensure kernel_size is odd\n",
    "            if kernel_size % 2 == 0:\n",
    "                kernel_size += 1\n",
    "            mask = cv2.GaussianBlur(mask, (kernel_size, kernel_size), self.mask_blur_radius)\n",
    "        return mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img = cv2.imread(self.image_paths[idx], cv2.IMREAD_UNCHANGED)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Failed to load image: {self.image_paths[idx]}\")\n",
    "        \n",
    "        # Handle different image formats (RGB, grayscale, etc.)\n",
    "        if len(img.shape) == 2:\n",
    "            # Grayscale image, convert to RGB\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        elif img.shape[2] == 4:\n",
    "            # RGBA image, convert to RGB\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)\n",
    "        else:\n",
    "            # BGR image, convert to RGB\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Resize image to target size\n",
    "        # Use INTER_AREA for better quality when downsampling (reduces blur)\n",
    "        img = cv2.resize(img, self.img_size, interpolation=cv2.INTER_AREA)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Load donor mask\n",
    "        donor_mask = cv2.imread(self.donor_mask_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        if donor_mask is None:\n",
    "            # If donor mask doesn't exist, create empty mask\n",
    "            donor_mask = np.zeros(self.img_size, dtype=np.uint8)\n",
    "        else:\n",
    "            # Resize donor mask to target size\n",
    "            donor_mask = cv2.resize(donor_mask, self.img_size, interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        # Load probe mask\n",
    "        probe_mask = cv2.imread(self.probe_mask_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        if probe_mask is None:\n",
    "            # If probe mask doesn't exist, create empty mask\n",
    "            probe_mask = np.zeros(self.img_size, dtype=np.uint8)\n",
    "        else:\n",
    "            # Resize probe mask to target size\n",
    "            probe_mask = cv2.resize(probe_mask, self.img_size, interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        # Combine donor and probe masks into a single mask\n",
    "        # Use maximum to combine both masks (union operation)\n",
    "        combined_mask = np.maximum(donor_mask, probe_mask)\n",
    "        \n",
    "        # Apply Gaussian blur for label smoothing if enabled\n",
    "        combined_mask = self._apply_mask_blur(combined_mask)\n",
    "        \n",
    "        # Normalize mask to [0, 1] range\n",
    "        combined_mask = combined_mask.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Convert to PyTorch tensors: (H, W, C) -> (C, H, W)\n",
    "        img = torch.from_numpy(img).permute(2, 0, 1)  # (3, H, W)\n",
    "        mask = torch.from_numpy(combined_mask).unsqueeze(0)  # (1, H, W)\n",
    "        \n",
    "        # Apply joint spatial transformations (rotation, flip) to both image and mask\n",
    "        if self.joint_transform:\n",
    "            img, mask = self.joint_transform(img, mask)\n",
    "        \n",
    "        # Apply image-only transformations (brightness, contrast, saturation)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        # Apply ImageNet normalization for MaxViT (pretrained on ImageNet)\n",
    "        # This should be applied AFTER all augmentations\n",
    "        # Mean and std for ImageNet normalization\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        img = (img - mean) / std\n",
    "        \n",
    "        # Classification label: All images in this dataset are forged\n",
    "        class_label = torch.tensor(1.0, dtype=torch.float32)\n",
    "        \n",
    "        return img, mask, class_label\n",
    "\n",
    "# Create augmentation transforms\n",
    "if config.USE_AUGMENTATION:\n",
    "    # Joint spatial transforms (applied to both image and mask)\n",
    "    # Only apply if individual switches are enabled\n",
    "    train_joint_transform = JointTransform(\n",
    "        rotation=config.AUG_ROTATION if config.AUG_ENABLE_ROTATION else 0,\n",
    "        hflip_prob=config.AUG_HFLIP if config.AUG_ENABLE_HFLIP else 0.0,\n",
    "        vflip_prob=config.AUG_VFLIP if config.AUG_ENABLE_VFLIP else 0.0,\n",
    "        enable_rotation=config.AUG_ENABLE_ROTATION,\n",
    "        enable_hflip=config.AUG_ENABLE_HFLIP,\n",
    "        enable_vflip=config.AUG_ENABLE_VFLIP\n",
    "    )\n",
    "    \n",
    "    # Image-only color transforms (only applied to image)\n",
    "    # Only apply if color augmentation is enabled\n",
    "    if config.AUG_ENABLE_COLOR:\n",
    "        train_image_transform = transforms.Compose([\n",
    "            transforms.ColorJitter(\n",
    "                brightness=config.AUG_BRIGHTNESS,\n",
    "                contrast=config.AUG_CONTRAST,\n",
    "                saturation=config.AUG_SATURATION,\n",
    "                hue=0.0  # Keep hue unchanged for forgery detection\n",
    "            )\n",
    "        ])\n",
    "    else:\n",
    "        train_image_transform = None\n",
    "    \n",
    "    # Validation: no augmentations\n",
    "    val_joint_transform = None\n",
    "    val_image_transform = None\n",
    "else:\n",
    "    # Master switch disabled - no augmentations\n",
    "    train_joint_transform = None\n",
    "    train_image_transform = None\n",
    "    val_joint_transform = None\n",
    "    val_image_transform = None\n",
    "\n",
    "# Print augmentation status\n",
    "print(f\"\\nAugmentation Configuration:\")\n",
    "print(f\"  Master Switch: {'ON' if config.USE_AUGMENTATION else 'OFF'}\")\n",
    "if config.USE_AUGMENTATION:\n",
    "    print(f\"  Spatial Augmentations:\")\n",
    "    print(f\"    Rotation: {'ON' if config.AUG_ENABLE_ROTATION else 'OFF'} (angle: ±{config.AUG_ROTATION}°)\")\n",
    "    print(f\"    Horizontal Flip: {'ON' if config.AUG_ENABLE_HFLIP else 'OFF'} (prob: {config.AUG_HFLIP})\")\n",
    "    print(f\"    Vertical Flip: {'ON' if config.AUG_ENABLE_VFLIP else 'OFF'} (prob: {config.AUG_VFLIP})\")\n",
    "    print(f\"  Color Augmentations: {'ON' if config.AUG_ENABLE_COLOR else 'OFF'}\")\n",
    "    if config.AUG_ENABLE_COLOR:\n",
    "        print(f\"    Brightness: ±{config.AUG_BRIGHTNESS}\")\n",
    "        print(f\"    Contrast: ±{config.AUG_CONTRAST}\")\n",
    "        print(f\"    Saturation: ±{config.AUG_SATURATION}\")\n",
    "\n",
    "# Initialize datasets\n",
    "# Training dataset with augmentations\n",
    "train_dataset = ImageMaskDataset(\n",
    "    image_folder=config.IMAGE_FOLDER,\n",
    "    donor_mask_folder=config.DONOR_MASK_FOLDER,\n",
    "    probe_mask_folder=config.PROBE_MASK_FOLDER,\n",
    "    img_size=config.IMG_SIZE,\n",
    "    transform=train_image_transform,\n",
    "    joint_transform=train_joint_transform,\n",
    "    mask_blur_radius=config.MASK_GAUSSIAN_BLUR_RADIUS\n",
    ")\n",
    "\n",
    "# Validation dataset without augmentations\n",
    "val_dataset = ImageMaskDataset(\n",
    "    image_folder=config.IMAGE_FOLDER,\n",
    "    donor_mask_folder=config.DONOR_MASK_FOLDER,\n",
    "    probe_mask_folder=config.PROBE_MASK_FOLDER,\n",
    "    img_size=config.IMG_SIZE,\n",
    "    transform=val_image_transform,\n",
    "    joint_transform=val_joint_transform,\n",
    "    mask_blur_radius=config.MASK_GAUSSIAN_BLUR_RADIUS\n",
    ")\n",
    "\n",
    "# Use train_dataset for indexing (both datasets have same structure)\n",
    "full_dataset = train_dataset\n",
    "\n",
    "print(f\"Total images: {len(full_dataset)}\")\n",
    "print(\"Note: All images in this dataset are forged (copymove forgeries)\")\n",
    "\n",
    "# Test one sample\n",
    "sample_img, sample_mask, sample_class = full_dataset[0]\n",
    "print(f\"\\nSample shape - Image: {sample_img.shape}, Mask: {sample_mask.shape}, Class: {sample_class}\")\n",
    "print(f\"Image dtype: {sample_img.dtype}, Mask dtype: {sample_mask.dtype}, Class dtype: {sample_class.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET SPLIT AND SETUP\n",
      "============================================================\n",
      "\n",
      "Dataset Split:\n",
      "  Total: 10523 images (all forged)\n",
      "  Train: 9470 images\n",
      "  Val: 1053 images\n",
      "\n",
      "DataLoaders created:\n",
      "  Train loader: 4735 batches\n",
      "  Validation loader: 527 batches\n",
      "\n",
      "============================================================\n",
      "Setup complete! Ready for training.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DATASET SPLIT AND SETUP\n",
    "# ============================================================================\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET SPLIT AND SETUP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create train/val split using random_split directly on datasets\n",
    "total_size = len(train_dataset)\n",
    "train_size = int(config.TRAIN_VAL_SPLIT * total_size)\n",
    "val_size = total_size - train_size\n",
    "\n",
    "# Split datasets directly (random_split returns Subset objects)\n",
    "train_dataset_split, val_dataset_split = random_split(\n",
    "    train_dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)  # For reproducibility\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset Split:\")\n",
    "print(f\"  Total: {total_size} images (all forged)\")\n",
    "print(f\"  Train: {len(train_dataset_split)} images\")\n",
    "print(f\"  Val: {len(val_dataset_split)} images\")\n",
    "\n",
    "# Create dataloaders (will be updated by curriculum learning if enabled)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset_split,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=config.NUM_WORKERS,\n",
    "    pin_memory=config.PIN_MEMORY\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset_split,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=config.NUM_WORKERS,\n",
    "    pin_memory=config.PIN_MEMORY\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoaders created:\")\n",
    "print(f\"  Train loader: {len(train_loader)} batches\")\n",
    "print(f\"  Validation loader: {len(val_loader)} batches\")\n",
    "\n",
    "# Initialize training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_iou': [],\n",
    "    'val_loss': [],\n",
    "    'val_iou': []\n",
    "}\n",
    "\n",
    "# Initialize early stopping parameters\n",
    "best_val_loss = float('inf')\n",
    "patience = config.PATIENCE\n",
    "patience_counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Setup complete! Ready for training.\")\n",
    "print(\"=\" * 60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curriculum learning is DISABLED in config.\n",
      "Set config.USE_CURRICULUM_LEARNING = True to enable.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CURRICULUM LEARNING: Sort masks by area and create progressive samplers\n",
    "# ============================================================================\n",
    "\n",
    "from torch.utils.data import Subset, WeightedRandomSampler\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Only run curriculum learning setup if enabled in config\n",
    "if config.USE_CURRICULUM_LEARNING:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"CURRICULUM LEARNING SETUP\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Step 1: Calculate mask areas for all training samples\n",
    "    print(\"\\nStep 1: Calculating mask areas for all training samples...\")\n",
    "    train_mask_areas = []\n",
    "    train_indices = []\n",
    "\n",
    "    # Get all indices from train_dataset_split (it's a Subset)\n",
    "    for subset_idx in tqdm(range(len(train_dataset_split)), desc=\"Computing train mask areas\"):\n",
    "        _, mask, _ = train_dataset_split[subset_idx]\n",
    "        # Calculate mask area (number of non-zero pixels)\n",
    "        area = mask.sum().item()  # Sum of all mask pixels\n",
    "        train_mask_areas.append(area)\n",
    "        train_indices.append(subset_idx)\n",
    "\n",
    "    train_mask_areas = np.array(train_mask_areas)\n",
    "    train_indices = np.array(train_indices)\n",
    "\n",
    "    print(f\"  Total training samples: {len(train_mask_areas)}\")\n",
    "    print(f\"  Mask area range: {train_mask_areas.min():.0f} - {train_mask_areas.max():.0f} pixels\")\n",
    "    print(f\"  Mean mask area: {train_mask_areas.mean():.1f} pixels\")\n",
    "    print(f\"  Median mask area: {np.median(train_mask_areas):.1f} pixels\")\n",
    "\n",
    "    # Step 1b: Calculate mask areas for all validation samples\n",
    "    print(\"\\nStep 1b: Calculating mask areas for all validation samples...\")\n",
    "    val_mask_areas = []\n",
    "    val_indices = []\n",
    "\n",
    "    for subset_idx in tqdm(range(len(val_dataset_split)), desc=\"Computing val mask areas\"):\n",
    "        _, mask, _ = val_dataset_split[subset_idx]\n",
    "        area = mask.sum().item()\n",
    "        val_mask_areas.append(area)\n",
    "        val_indices.append(subset_idx)\n",
    "\n",
    "    val_mask_areas = np.array(val_mask_areas)\n",
    "    val_indices = np.array(val_indices)\n",
    "\n",
    "    print(f\"  Total validation samples: {len(val_mask_areas)}\")\n",
    "    print(f\"  Mask area range: {val_mask_areas.min():.0f} - {val_mask_areas.max():.0f} pixels\")\n",
    "    print(f\"  Mean mask area: {val_mask_areas.mean():.1f} pixels\")\n",
    "    print(f\"  Median mask area: {np.median(val_mask_areas):.1f} pixels\")\n",
    "\n",
    "    # Step 2: Sort by area (descending - largest masks first = easiest)\n",
    "    print(\"\\nStep 2: Sorting samples by mask area (descending)...\")\n",
    "    # Sort training set\n",
    "    train_sorted_indices = np.argsort(train_mask_areas)[::-1]  # Descending order\n",
    "    train_sorted_areas = train_mask_areas[train_sorted_indices]\n",
    "    train_sorted_indices_list = train_indices[train_sorted_indices]\n",
    "    \n",
    "    # Sort validation set\n",
    "    val_sorted_indices = np.argsort(val_mask_areas)[::-1]  # Descending order\n",
    "    val_sorted_areas = val_mask_areas[val_sorted_indices]\n",
    "    val_sorted_indices_list = val_indices[val_sorted_indices]\n",
    "\n",
    "    print(f\"  Train - Largest mask area: {train_sorted_areas[0]:.0f} pixels, Smallest: {train_sorted_areas[-1]:.0f} pixels\")\n",
    "    print(f\"  Val - Largest mask area: {val_sorted_areas[0]:.0f} pixels, Smallest: {val_sorted_areas[-1]:.0f} pixels\")\n",
    "\n",
    "    # Step 3: Split into 10 groups with decreasing area\n",
    "    print(\"\\nStep 3: Splitting into 10 groups by area...\")\n",
    "    num_groups = 10\n",
    "    \n",
    "    # Split training set\n",
    "    train_group_size = len(train_sorted_indices_list) // num_groups\n",
    "    train_groups = []\n",
    "    for i in range(num_groups):\n",
    "        start_idx = i * train_group_size\n",
    "        if i == num_groups - 1:\n",
    "            end_idx = len(train_sorted_indices_list)\n",
    "        else:\n",
    "            end_idx = (i + 1) * train_group_size\n",
    "        \n",
    "        group_indices = train_sorted_indices_list[start_idx:end_idx]\n",
    "        group_areas = train_sorted_areas[start_idx:end_idx]\n",
    "        train_groups.append({\n",
    "            'indices': group_indices,\n",
    "            'areas': group_areas,\n",
    "            'mean_area': group_areas.mean(),\n",
    "            'size': len(group_indices)\n",
    "        })\n",
    "        \n",
    "        print(f\"  Train Group {i+1}: {len(group_indices)} samples, \"\n",
    "              f\"mean area: {group_areas.mean():.1f} pixels \"\n",
    "              f\"(range: {group_areas.min():.0f} - {group_areas.max():.0f})\")\n",
    "    \n",
    "    # Split validation set\n",
    "    val_group_size = len(val_sorted_indices_list) // num_groups\n",
    "    val_groups = []\n",
    "    for i in range(num_groups):\n",
    "        start_idx = i * val_group_size\n",
    "        if i == num_groups - 1:\n",
    "            end_idx = len(val_sorted_indices_list)\n",
    "        else:\n",
    "            end_idx = (i + 1) * val_group_size\n",
    "        \n",
    "        group_indices = val_sorted_indices_list[start_idx:end_idx]\n",
    "        group_areas = val_sorted_areas[start_idx:end_idx]\n",
    "        val_groups.append({\n",
    "            'indices': group_indices,\n",
    "            'areas': group_areas,\n",
    "            'mean_area': group_areas.mean(),\n",
    "            'size': len(group_indices)\n",
    "        })\n",
    "        \n",
    "        print(f\"  Val Group {i+1}: {len(group_indices)} samples, \"\n",
    "              f\"mean area: {group_areas.mean():.1f} pixels \"\n",
    "              f\"(range: {group_areas.min():.0f} - {group_areas.max():.0f})\")\n",
    "\n",
    "    # Step 4: Create curriculum learning samplers for both train and val\n",
    "    print(\"\\nStep 4: Creating curriculum learning samplers (adjacent pairs)...\")\n",
    "\n",
    "    # Calculate epoch boundaries\n",
    "    num_epochs = config.NUM_EPOCHS\n",
    "    first_half_epochs = num_epochs // 2\n",
    "    second_half_epochs = num_epochs - first_half_epochs\n",
    "\n",
    "    # Create stages with two adjacent groups at a time\n",
    "    # We have 10 groups, so we can create 9 stages: (1-2), (2-3), (3-4), ..., (9-10)\n",
    "    num_curriculum_stages = num_groups - 1  # 9 stages for 10 groups\n",
    "    \n",
    "    # Epochs per stage in first half\n",
    "    epochs_per_stage = max(1, first_half_epochs // num_curriculum_stages)\n",
    "\n",
    "    print(f\"  Total epochs: {num_epochs}\")\n",
    "    print(f\"  First half (curriculum): {first_half_epochs} epochs\")\n",
    "    print(f\"  Second half (full dataset): {second_half_epochs} epochs\")\n",
    "    print(f\"  Number of curriculum stages: {num_curriculum_stages} (each uses 2 adjacent groups)\")\n",
    "    print(f\"  Epochs per stage: ~{epochs_per_stage}\")\n",
    "\n",
    "    # Create samplers for each curriculum stage (for both train and val)\n",
    "    train_curriculum_samplers = []\n",
    "    val_curriculum_samplers = []\n",
    "\n",
    "    # Create stages with two adjacent groups: (1-2), (2-3), (3-4), ..., (9-10)\n",
    "    for stage_idx in range(num_curriculum_stages):\n",
    "        # Each stage uses groups [stage_idx] and [stage_idx+1] (0-indexed)\n",
    "        group_start = stage_idx\n",
    "        group_end = stage_idx + 1\n",
    "        \n",
    "        # Combine indices from two adjacent groups for training\n",
    "        train_combined_indices = np.concatenate([\n",
    "            train_groups[group_start]['indices'],\n",
    "            train_groups[group_end]['indices']\n",
    "        ])\n",
    "        train_sampler_indices = train_combined_indices.tolist()\n",
    "        \n",
    "        # Combine indices from two adjacent groups for validation\n",
    "        val_combined_indices = np.concatenate([\n",
    "            val_groups[group_start]['indices'],\n",
    "            val_groups[group_end]['indices']\n",
    "        ])\n",
    "        val_sampler_indices = val_combined_indices.tolist()\n",
    "        \n",
    "        # Calculate mean area for the two groups\n",
    "        train_combined_areas = np.concatenate([\n",
    "            train_groups[group_start]['areas'],\n",
    "            train_groups[group_end]['areas']\n",
    "        ])\n",
    "        val_combined_areas = np.concatenate([\n",
    "            val_groups[group_start]['areas'],\n",
    "            val_groups[group_end]['areas']\n",
    "        ])\n",
    "        \n",
    "        train_curriculum_samplers.append({\n",
    "            'groups_used': f\"{group_start+1}-{group_end+1}\",  # 1-indexed for display\n",
    "            'group_start': group_start + 1,  # 1-indexed\n",
    "            'group_end': group_end + 1,  # 1-indexed\n",
    "            'indices': train_sampler_indices,\n",
    "            'size': len(train_sampler_indices),\n",
    "            'mean_area': train_combined_areas.mean()\n",
    "        })\n",
    "        \n",
    "        val_curriculum_samplers.append({\n",
    "            'groups_used': f\"{group_start+1}-{group_end+1}\",  # 1-indexed for display\n",
    "            'group_start': group_start + 1,  # 1-indexed\n",
    "            'group_end': group_end + 1,  # 1-indexed\n",
    "            'indices': val_sampler_indices,\n",
    "            'size': len(val_sampler_indices),\n",
    "            'mean_area': val_combined_areas.mean()\n",
    "        })\n",
    "        \n",
    "        print(f\"  Stage {stage_idx+1}: Groups {group_start+1}-{group_end+1} - \"\n",
    "              f\"Train={len(train_sampler_indices)} samples (mean area: {train_curriculum_samplers[-1]['mean_area']:.1f}), \"\n",
    "              f\"Val={len(val_sampler_indices)} samples (mean area: {val_curriculum_samplers[-1]['mean_area']:.1f})\")\n",
    "\n",
    "    # Full dataset samplers (for second half)\n",
    "    train_full_indices = np.concatenate([train_groups[i]['indices'] for i in range(num_groups)]).tolist()\n",
    "    val_full_indices = np.concatenate([val_groups[i]['indices'] for i in range(num_groups)]).tolist()\n",
    "    \n",
    "    train_full_dataset_sampler = {\n",
    "        'groups_used': 'all',\n",
    "        'indices': train_full_indices,\n",
    "        'size': len(train_full_indices),\n",
    "        'mean_area': train_mask_areas.mean()\n",
    "    }\n",
    "    \n",
    "    val_full_dataset_sampler = {\n",
    "        'groups_used': 'all',\n",
    "        'indices': val_full_indices,\n",
    "        'size': len(val_full_indices),\n",
    "        'mean_area': val_mask_areas.mean()\n",
    "    }\n",
    "\n",
    "    print(f\"  Full dataset - Train: {len(train_full_indices)} samples, Val: {len(val_full_indices)} samples\")\n",
    "\n",
    "    # Step 5: Create function to get sampler for a given epoch\n",
    "    def get_curriculum_sampler(epoch):\n",
    "        \"\"\"\n",
    "        Returns indices to use for a given epoch based on curriculum learning schedule.\n",
    "        \n",
    "        First half: Adjacent pairs (groups 1-2, then 2-3, then 3-4, ..., then 9-10)\n",
    "        Second half: Full dataset\n",
    "        \n",
    "        Returns:\n",
    "            train_indices, train_sampler_info, val_indices, val_sampler_info\n",
    "        \"\"\"\n",
    "        if epoch < first_half_epochs:\n",
    "            # Adjacent pairs curriculum: determine which stage based on epoch\n",
    "            stage = min(epoch // epochs_per_stage, num_curriculum_stages - 1)  # 0 to 8 (9 stages)\n",
    "            train_sampler_info = train_curriculum_samplers[stage]\n",
    "            val_sampler_info = val_curriculum_samplers[stage]\n",
    "            return train_sampler_info['indices'], train_sampler_info, val_sampler_info['indices'], val_sampler_info\n",
    "        else:\n",
    "            # Second half: use full dataset\n",
    "            return train_full_dataset_sampler['indices'], train_full_dataset_sampler, val_full_dataset_sampler['indices'], val_full_dataset_sampler\n",
    "\n",
    "    # Step 6: Create helper function to create DataLoaders with curriculum sampler\n",
    "    def create_curriculum_dataloader(epoch):\n",
    "        \"\"\"\n",
    "        Creates DataLoaders for the given epoch using curriculum learning.\n",
    "        \n",
    "        Args:\n",
    "            epoch: Current epoch number (0-indexed)\n",
    "        \n",
    "        Returns:\n",
    "            train_loader: DataLoader for the current curriculum stage (training)\n",
    "            train_sampler_info: Dictionary with information about the training sampler\n",
    "            val_loader: DataLoader for the current curriculum stage (validation)\n",
    "            val_sampler_info: Dictionary with information about the validation sampler\n",
    "        \"\"\"\n",
    "        train_indices, train_sampler_info, val_indices, val_sampler_info = get_curriculum_sampler(epoch)\n",
    "        \n",
    "        # Create Subsets using the selected indices\n",
    "        train_curriculum_subset = Subset(train_dataset_split, train_indices)\n",
    "        val_curriculum_subset = Subset(val_dataset_split, val_indices)\n",
    "        \n",
    "        # Create DataLoaders with the curriculum subsets\n",
    "        train_loader = DataLoader(\n",
    "            train_curriculum_subset,\n",
    "            batch_size=config.BATCH_SIZE,\n",
    "            shuffle=True,  # Shuffle within the selected subset\n",
    "            num_workers=config.NUM_WORKERS,\n",
    "            pin_memory=config.PIN_MEMORY\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            val_curriculum_subset,\n",
    "            batch_size=config.BATCH_SIZE,\n",
    "            shuffle=False,  # No shuffle for validation\n",
    "            num_workers=config.NUM_WORKERS,\n",
    "            pin_memory=config.PIN_MEMORY\n",
    "        )\n",
    "        \n",
    "        return train_loader, train_sampler_info, val_loader, val_sampler_info\n",
    "\n",
    "    # Test the curriculum schedule\n",
    "    print(\"\\nStep 7: Curriculum schedule preview:\")\n",
    "    print(\"  Epoch Range    | Groups Used | Train Samples | Val Samples | Train Mean Area | Val Mean Area\")\n",
    "    print(\"  \" + \"-\" * 95)\n",
    "    for epoch in [0, first_half_epochs//10, first_half_epochs//5, first_half_epochs//2, \n",
    "                  first_half_epochs-1, first_half_epochs, num_epochs-1]:\n",
    "        train_indices, train_info, val_indices, val_info = get_curriculum_sampler(epoch)\n",
    "        groups_str = train_info['groups_used'] if isinstance(train_info['groups_used'], str) else \"all\"\n",
    "        print(f\"  Epoch {epoch:3d}      | {groups_str:10s} | {train_info['size']:13d} | {val_info['size']:11d} | \"\n",
    "              f\"{train_info['mean_area']:15.1f} | {val_info['mean_area']:13.1f}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Curriculum learning setup complete!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nUsage in training loop:\")\n",
    "    print(\"  for epoch in range(num_epochs):\")\n",
    "    print(\"      train_loader, train_info, val_loader, val_info = create_curriculum_dataloader(epoch)\")\n",
    "    print(\"      # Use train_loader and val_loader for training and validation...\")\n",
    "else:\n",
    "    print(\"Curriculum learning is DISABLED in config.\")\n",
    "    print(\"Set config.USE_CURRICULUM_LEARNING = True to enable.\")\n",
    "    # Create dummy functions that won't be used\n",
    "    def get_curriculum_sampler(epoch):\n",
    "        return None, None, None, None\n",
    "    def create_curriculum_dataloader(epoch):\n",
    "        return None, None, None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5981597,
     "status": "ok",
     "timestamp": 1751822053708,
     "user": {
      "displayName": "JAYESH SHARMA",
      "userId": "10181368842352240411"
     },
     "user_tz": -330
    },
    "id": "vmaKQh1WaFk0",
    "outputId": "efcc0038-ab88-4787-8a03-370e6dcf3c38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "✓ GPU supports bfloat16 - Using AMP with bfloat16\n",
      "\n",
      "Output directories created:\n",
      "  Main output: outputs/\n",
      "  Visualizations: outputs/visualizations/\n",
      "  Checkpoints: outputs/checkpoints/\n",
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "Total epochs: 30\n",
      "Curriculum Learning: DISABLED\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [Train]:   0%|          | 5/4735 [00:33<8:47:25,  6.69s/it, loss=0.0601, iou=0.773]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 329\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;66;03m# Use scaler for gradient scaling (important for fp16, optional for bf16)\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 329\u001b[0m     \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;66;03m# Unscale gradients before clipping (required when using scaler)\u001b[39;00m\n\u001b[0;32m    331\u001b[0m     scaler\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n",
      "File \u001b[1;32mc:\\Users\\GAMER\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    646\u001b[0m     )\n\u001b[1;32m--> 647\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\GAMER\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\GAMER\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.amp import autocast, GradScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Check bfloat16 support and setup AMP\n",
    "if torch.cuda.is_available():\n",
    "    # Check if GPU supports bfloat16 (Ampere architecture and later: A100, RTX 30xx, RTX 40xx, etc.)\n",
    "    if torch.cuda.is_bf16_supported():\n",
    "        use_bf16 = True\n",
    "        amp_dtype = torch.bfloat16\n",
    "        print(f\"✓ GPU supports bfloat16 - Using AMP with bfloat16\")\n",
    "    else:\n",
    "        use_bf16 = False\n",
    "        amp_dtype = torch.float16\n",
    "        print(f\"⚠ GPU does not support bfloat16 - Falling back to float16\")\n",
    "else:\n",
    "    use_bf16 = False\n",
    "    amp_dtype = None\n",
    "    print(f\"⚠ CUDA not available - AMP disabled\")\n",
    "\n",
    "# Create GradScaler for AMP\n",
    "# Note: bfloat16 typically doesn't need scaling, but using scaler is still recommended for safety\n",
    "scaler = GradScaler('cuda') if device.type == 'cuda' else None\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(config.VIZ_DIR, exist_ok=True)\n",
    "os.makedirs(config.CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"\\nOutput directories created:\")\n",
    "print(f\"  Main output: {config.OUTPUT_DIR}/\")\n",
    "print(f\"  Visualizations: {config.VIZ_DIR}/\")\n",
    "print(f\"  Checkpoints: {config.CHECKPOINT_DIR}/\")\n",
    "\n",
    "# Set paths for visualization and checkpoints\n",
    "viz_dir = config.VIZ_DIR\n",
    "checkpoint_dir = config.CHECKPOINT_DIR\n",
    "\n",
    "def denormalize_imagenet(img_tensor):\n",
    "    \"\"\"\n",
    "    Denormalize ImageNet-normalized images for correct display.\n",
    "    \n",
    "    Args:\n",
    "        img_tensor: Tensor of shape (B, C, H, W) or (B, H, W, C) or (C, H, W) or numpy array of shape (H, W, C)\n",
    "                    with ImageNet normalization applied\n",
    "    \n",
    "    Returns:\n",
    "        Denormalized image in range [0, 1] ready for display\n",
    "    \"\"\"\n",
    "    # ImageNet mean and std\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    # Handle different input formats\n",
    "    if isinstance(img_tensor, torch.Tensor):\n",
    "        img_np = img_tensor.cpu().numpy()\n",
    "    else:\n",
    "        img_np = img_tensor.copy()\n",
    "    \n",
    "    # Handle different tensor shapes\n",
    "    if len(img_np.shape) == 4:  # Batch dimension present\n",
    "        # Check if it's (B, C, H, W) or (B, H, W, C)\n",
    "        if img_np.shape[1] == 3:  # (B, C, H, W)\n",
    "            # Permute to (B, H, W, C) for easier broadcasting\n",
    "            img_np = img_np.transpose(0, 2, 3, 1)\n",
    "        # img_np is now (B, H, W, C)\n",
    "        # Denormalize: img = img * std + mean\n",
    "        img_np = img_np * std + mean\n",
    "    elif len(img_np.shape) == 3:\n",
    "        if img_np.shape[0] == 3:  # (C, H, W)\n",
    "            # Permute to (H, W, C)\n",
    "            img_np = img_np.transpose(1, 2, 0)\n",
    "        # img_np is now (H, W, C)\n",
    "        img_np = img_np * std + mean\n",
    "    \n",
    "    # Clip to valid range [0, 1]\n",
    "    img_np = np.clip(img_np, 0, 1)\n",
    "    \n",
    "    return img_np\n",
    "\n",
    "\n",
    "def save_visualization(images, masks, predictions, epoch, split='train', num_images=2):\n",
    "    \"\"\"\n",
    "    Save visualization images showing original, GT mask, predicted mask, and overlay.\n",
    "    \n",
    "    Args:\n",
    "        images: Tensor of shape (B, C, H, W) - original images (ImageNet normalized)\n",
    "        masks: Tensor of shape (B, 1, H, W) - ground truth masks\n",
    "        predictions: Tensor of shape (B, 1, H, W) - predicted masks\n",
    "        epoch: Current epoch number\n",
    "        split: 'train' or 'val'\n",
    "        num_images: Number of images to save\n",
    "    \"\"\"\n",
    "    # Convert tensors to numpy and move to CPU\n",
    "    # Convert to float32 first to handle bfloat16/float16 from AMP\n",
    "    images_np = images.cpu().permute(0, 2, 3, 1).float().numpy()  # (B, H, W, C)\n",
    "    masks_np = masks.cpu().squeeze(1).float().numpy()  # (B, H, W)\n",
    "    preds_np = predictions.cpu().squeeze(1).float().numpy()  # (B, H, W)\n",
    "    \n",
    "    # Denormalize images for correct display (reverse ImageNet normalization)\n",
    "    images_np = denormalize_imagenet(images_np)\n",
    "    \n",
    "    # Threshold predictions\n",
    "    preds_binary = (preds_np > 0.5).astype(np.float32)\n",
    "    \n",
    "    # All images are forged, so just select random images\n",
    "    batch_size = masks_np.shape[0]\n",
    "    num_images_to_show = min(num_images, batch_size)\n",
    "    selected_indices = np.random.choice(batch_size, size=num_images_to_show, replace=False)\n",
    "    \n",
    "    # Save selected images\n",
    "    for img_idx, i in enumerate(selected_indices):\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "        \n",
    "        # Original image (already denormalized)\n",
    "        img = images_np[i]\n",
    "        axes[0].imshow(img)\n",
    "        axes[0].set_title('Original Image (Forged)')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Ground truth mask\n",
    "        axes[1].imshow(masks_np[i], cmap='gray')\n",
    "        axes[1].set_title('Ground Truth Mask')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        # Predicted mask\n",
    "        axes[2].imshow(preds_binary[i], cmap='gray')\n",
    "        axes[2].set_title('Predicted Mask')\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        # Overlay: original image with predicted mask in red\n",
    "        overlay = img.copy()\n",
    "        # Create colored mask (red channel)\n",
    "        mask_colored = np.zeros_like(overlay)\n",
    "        mask_colored[:, :, 0] = preds_binary[i]  # Red channel\n",
    "        # Blend original with colored mask\n",
    "        overlay = np.clip(overlay * 0.6 + mask_colored * 0.4, 0, 1)\n",
    "        axes[3].imshow(overlay)\n",
    "        axes[3].set_title('Overlay (Original + Prediction)')\n",
    "        axes[3].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        save_path = os.path.join(viz_dir, f'epoch_{epoch:03d}_{split}_{img_idx+1}.png')\n",
    "        # Increased DPI from 100 to 150 for sharper visualization images (especially for 512x512)\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "# Loss functions\n",
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Dice Loss for binary segmentation\"\"\"\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        # Flatten tensors\n",
    "        predictions = predictions.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        # Calculate Dice coefficient\n",
    "        intersection = (predictions * targets).sum()\n",
    "        dice = (2. * intersection + self.smooth) / (predictions.sum() + targets.sum() + self.smooth)\n",
    "        \n",
    "        # Return Dice loss (1 - Dice coefficient)\n",
    "        return 1 - dice\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss for binary segmentation - addresses class imbalance\"\"\"\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, logits, targets):\n",
    "        # Apply sigmoid to get probabilities\n",
    "        probs = torch.sigmoid(logits)\n",
    "        \n",
    "        # Calculate BCE loss\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n",
    "        \n",
    "        # Calculate p_t (probability of true class)\n",
    "        p_t = probs * targets + (1 - probs) * (1 - targets)\n",
    "        \n",
    "        # Calculate alpha_t (alpha for true class)\n",
    "        alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
    "        \n",
    "        # Calculate focal weight\n",
    "        focal_weight = alpha_t * (1 - p_t) ** self.gamma\n",
    "        \n",
    "        # Apply focal weight to BCE loss\n",
    "        focal_loss = focal_weight * bce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"Combined Focal and Dice Loss for segmentation\"\"\"\n",
    "    def __init__(self, focal_weight=0.5, dice_weight=0.5, dice_smooth=1e-6, focal_alpha=0.25, focal_gamma=2.0):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.focal_weight = focal_weight\n",
    "        self.dice_weight = dice_weight\n",
    "        # FocalLoss expects logits, applies sigmoid internally\n",
    "        self.focal_loss = FocalLoss(alpha=focal_alpha, gamma=focal_gamma)\n",
    "        self.dice_loss = DiceLoss(smooth=dice_smooth)\n",
    "    \n",
    "    def forward(self, mask_logits, mask_targets):\n",
    "        # Segmentation loss (Focal + Dice)\n",
    "        # FocalLoss expects logits, applies sigmoid internally\n",
    "        seg_focal = self.focal_loss(mask_logits, mask_targets)\n",
    "        # DiceLoss expects probabilities, so apply sigmoid to logits\n",
    "        mask_probs = torch.sigmoid(mask_logits)\n",
    "        seg_dice = self.dice_loss(mask_probs, mask_targets)\n",
    "        seg_loss = self.focal_weight * seg_focal + self.dice_weight * seg_dice\n",
    "        \n",
    "        return seg_loss\n",
    "\n",
    "# Create combined loss function\n",
    "criterion = CombinedLoss(\n",
    "    focal_weight=config.FOCAL_WEIGHT,\n",
    "    dice_weight=config.DICE_WEIGHT,\n",
    "    dice_smooth=config.DICE_SMOOTH,\n",
    "    focal_alpha=config.FOCAL_ALPHA,\n",
    "    focal_gamma=config.FOCAL_GAMMA\n",
    ")\n",
    "\n",
    "if config.OPTIMIZER.lower() == 'adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)\n",
    "elif config.OPTIMIZER.lower() == 'sgd':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY, momentum=0.9)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown optimizer: {config.OPTIMIZER}. Use 'adam' or 'sgd'.\")\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING LOOP\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total epochs: {config.NUM_EPOCHS}\")\n",
    "print(f\"Curriculum Learning: {'ENABLED' if config.USE_CURRICULUM_LEARNING else 'DISABLED'}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = config.NUM_EPOCHS\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Use curriculum learning if enabled\n",
    "    if config.USE_CURRICULUM_LEARNING and 'create_curriculum_dataloader' in globals():\n",
    "        new_train_loader, train_sampler_info, new_val_loader, val_sampler_info = create_curriculum_dataloader(epoch)\n",
    "        # Only update loaders if valid loaders were returned\n",
    "        if new_train_loader is not None:\n",
    "            train_loader = new_train_loader\n",
    "        if new_val_loader is not None:\n",
    "            val_loader = new_val_loader\n",
    "        if train_sampler_info is not None and val_sampler_info is not None:\n",
    "            groups_str = train_sampler_info['groups_used'] if isinstance(train_sampler_info['groups_used'], str) else \"all\"\n",
    "            print(f\"\\nEpoch {epoch+1}: Using curriculum groups {groups_str}\")\n",
    "            print(f\"  Train: {train_sampler_info['size']} samples (mean area: {train_sampler_info['mean_area']:.1f})\")\n",
    "            print(f\"  Val: {val_sampler_info['size']} samples (mean area: {val_sampler_info['mean_area']:.1f})\")\n",
    "    \n",
    "    # Calculate number of batches for random selection\n",
    "    # Ensure train_loader and val_loader exist and are valid\n",
    "    if train_loader is None:\n",
    "        raise ValueError(\"train_loader is None! Make sure dataset split cell (Cell 4) was run.\")\n",
    "    if val_loader is None:\n",
    "        raise ValueError(\"val_loader is None! Make sure dataset split cell (Cell 4) was run.\")\n",
    "    num_train_batches = len(train_loader)\n",
    "    num_val_batches = len(val_loader)\n",
    "    \n",
    "    # Randomly select a batch index for visualization this epoch\n",
    "    # Ensure we have at least one batch, and use safe random selection\n",
    "    if num_train_batches > 0:\n",
    "        random_train_batch_idx = random.randint(0, num_train_batches - 1)\n",
    "    else:\n",
    "        random_train_batch_idx = 0\n",
    "    \n",
    "    if num_val_batches > 0:\n",
    "        random_val_batch_idx = random.randint(0, num_val_batches - 1)\n",
    "    else:\n",
    "        random_val_batch_idx = 0\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_iou_sum = 0.0\n",
    "    train_batches = 0\n",
    "    train_images_batch = None\n",
    "    train_masks_batch = None\n",
    "    train_outputs_batch = None\n",
    "    \n",
    "    train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config.NUM_EPOCHS} [Train]')\n",
    "    \n",
    "    for batch_idx, (images, masks, class_labels) in enumerate(train_pbar):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # Forward pass with AMP (Automatic Mixed Precision)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Use autocast context for forward pass (uses bfloat16 or float16)\n",
    "        with autocast(device_type='cuda', dtype=amp_dtype):\n",
    "            mask_outputs = model(images)\n",
    "            \n",
    "            # Calculate loss (segmentation only)\n",
    "            loss = criterion(mask_outputs, masks)\n",
    "        \n",
    "        # Backward pass\n",
    "        # Use scaler for gradient scaling (important for fp16, optional for bf16)\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            # Unscale gradients before clipping (required when using scaler)\n",
    "            scaler.unscale_(optimizer)\n",
    "            # Clip gradient norm to 1.0\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            # Clip gradient norm to 1.0\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Save batch for visualization - always save first batch, or randomly selected batch\n",
    "        # This ensures we always have visualizations even if random selection fails\n",
    "        if batch_idx == 0 or batch_idx == random_train_batch_idx:\n",
    "            train_images_batch = images.detach().clone()\n",
    "            train_masks_batch = masks.detach().clone()\n",
    "            train_outputs_batch = torch.sigmoid(mask_outputs.detach().clone())  # Convert logits to probs\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # IoU for segmentation (apply sigmoid to logits first)\n",
    "        mask_probs = torch.sigmoid(mask_outputs)\n",
    "        predicted = (mask_probs > 0.5).float()\n",
    "        intersection = (predicted * masks).sum(dim=(1, 2, 3))\n",
    "        union = predicted.sum(dim=(1, 2, 3)) + masks.sum(dim=(1, 2, 3)) - intersection\n",
    "        iou = (intersection / (union + 1e-6)).mean()\n",
    "        train_iou_sum += iou.item()\n",
    "        \n",
    "        train_batches += 1\n",
    "        \n",
    "        train_pbar.set_postfix({\n",
    "            'loss': loss.item(),\n",
    "            'iou': iou.item()\n",
    "        })\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_iou = train_iou_sum / train_batches if train_batches > 0 else 0.0\n",
    "    \n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    history['train_iou'].append(train_iou)\n",
    "    \n",
    "    # Save training visualizations (should always be available since we save batch 0)\n",
    "    if train_images_batch is not None:\n",
    "        try:\n",
    "            save_visualization(train_images_batch, train_masks_batch, train_outputs_batch, \n",
    "                             epoch + 1, split='train', num_images=config.NUM_VIZ_IMAGES)\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Failed to save training visualizations: {e}\")\n",
    "    else:\n",
    "        print(f\"  Warning: No training batch captured for visualization in epoch {epoch + 1}\")\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_iou_sum = 0.0\n",
    "    val_batches = 0\n",
    "    val_images_batch = None\n",
    "    val_masks_batch = None\n",
    "    val_outputs_batch = None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{config.NUM_EPOCHS} [Val]')\n",
    "        for batch_idx, (images, masks, class_labels) in enumerate(val_pbar):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Use autocast for validation forward pass as well\n",
    "            with autocast(device_type='cuda', dtype=amp_dtype):\n",
    "                mask_outputs = model(images)\n",
    "                loss = criterion(mask_outputs, masks)\n",
    "            \n",
    "            # Save batch for visualization - always save first batch, or randomly selected batch\n",
    "            # This ensures we always have visualizations even if random selection fails\n",
    "            if batch_idx == 0 or batch_idx == random_val_batch_idx:\n",
    "                val_images_batch = images.clone()  # Already in no_grad context\n",
    "                val_masks_batch = masks.clone()\n",
    "                val_outputs_batch = torch.sigmoid(mask_outputs.clone())  # Convert logits to probs\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # IoU for segmentation (apply sigmoid to logits first)\n",
    "            mask_probs = torch.sigmoid(mask_outputs)\n",
    "            predicted = (mask_probs > 0.5).float()\n",
    "            intersection = (predicted * masks).sum(dim=(1, 2, 3))\n",
    "            union = predicted.sum(dim=(1, 2, 3)) + masks.sum(dim=(1, 2, 3)) - intersection\n",
    "            iou = (intersection / (union + 1e-6)).mean()\n",
    "            val_iou_sum += iou.item()\n",
    "            \n",
    "            val_batches += 1\n",
    "            \n",
    "            val_pbar.set_postfix({\n",
    "                'loss': loss.item(),\n",
    "                'iou': iou.item()\n",
    "            })\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_iou = val_iou_sum / val_batches if val_batches > 0 else 0.0\n",
    "    \n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "    history['val_iou'].append(val_iou)\n",
    "    \n",
    "    # Save validation visualizations (should always be available since we save batch 0)\n",
    "    if val_images_batch is not None:\n",
    "        try:\n",
    "            save_visualization(val_images_batch, val_masks_batch, val_outputs_batch, \n",
    "                             epoch + 1, split='val', num_images=config.NUM_VIZ_IMAGES)\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Failed to save validation visualizations: {e}\")\n",
    "    else:\n",
    "        print(f\"  Warning: No validation batch captured for visualization in epoch {epoch + 1}\")\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{config.NUM_EPOCHS}:')\n",
    "    print(f'  Train Loss: {avg_train_loss:.4f}, Train IoU: {train_iou:.4f}')\n",
    "    print(f'  Val Loss: {avg_val_loss:.4f}, Val IoU: {val_iou:.4f}')\n",
    "    print(f'  Visualizations saved to {viz_dir}/')\n",
    "    \n",
    "    # Model checkpointing\n",
    "    if avg_val_loss < best_val_loss - config.MIN_DELTA:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, config.MODEL_SAVE_NAME)\n",
    "        torch.save(best_model_state, checkpoint_path)\n",
    "        print(f'  ✓ Model saved to {checkpoint_path}! (Val Loss: {avg_val_loss:.4f})')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f'  No improvement. Patience: {patience_counter}/{patience}')\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= patience:\n",
    "        print(f'\\nEarly stopping triggered after {epoch+1} epochs')\n",
    "        break\n",
    "\n",
    "# Load best model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f'\\nBest model loaded with validation loss: {best_val_loss:.4f}')\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss Evolution')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# IoU\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_iou'], label='Train IoU')\n",
    "plt.plot(history['val_iou'], label='Val IoU')\n",
    "plt.legend()\n",
    "plt.title('IoU Evolution')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('IoU')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "executionInfo": {
     "elapsed": 6280,
     "status": "ok",
     "timestamp": 1751822127206,
     "user": {
      "displayName": "JAYESH SHARMA",
      "userId": "10181368842352240411"
     },
     "user_tz": -330
    },
    "id": "kMIvR9l5vCGx",
    "outputId": "5ac46bdb-2fa3-4041-dc06-b1b86b9272b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected 20 images from validation dataset (indices: [343 883 108 584 922 325 562 475  74   7 104  82 969 950 171 480 727 600\n",
      " 707 513])\n"
     ]
    }
   ],
   "source": [
    "# Import AMP if not already imported (for standalone execution)\n",
    "try:\n",
    "    from torch.amp import autocast\n",
    "    # Check if amp_dtype is defined (from training cell)\n",
    "    if 'amp_dtype' not in globals():\n",
    "        # Setup AMP for inference\n",
    "        if torch.cuda.is_available() and torch.cuda.is_bf16_supported():\n",
    "            amp_dtype = torch.bfloat16\n",
    "            print(\"✓ Using AMP with bfloat16 for inference\")\n",
    "        elif torch.cuda.is_available():\n",
    "            amp_dtype = torch.float16\n",
    "            print(\"⚠ Using AMP with float16 for inference\")\n",
    "        else:\n",
    "            amp_dtype = None\n",
    "except ImportError:\n",
    "    amp_dtype = None\n",
    "\n",
    "# Load the best saved model\n",
    "checkpoint_path = os.path.join(config.CHECKPOINT_DIR, config.MODEL_SAVE_NAME)\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Test prediction on 20 randomly selected images from validation dataset\n",
    "num_test_images = 20\n",
    "val_size = len(val_dataset_split)\n",
    "num_test_images = min(num_test_images, val_size)  # Don't exceed dataset size\n",
    "\n",
    "# Randomly select indices from validation dataset\n",
    "random_indices = np.random.choice(val_size, size=num_test_images, replace=False)\n",
    "print(f\"Randomly selected {num_test_images} images from validation dataset (indices: {random_indices})\")\n",
    "\n",
    "# Collect images, masks, and predictions\n",
    "test_images = []\n",
    "test_masks = []\n",
    "test_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx in random_indices:\n",
    "        # Get image and mask from dataset\n",
    "        img_tensor, mask_tensor, _ = val_dataset_split[idx]\n",
    "        \n",
    "        # Move to device and add batch dimension\n",
    "        img_batch = img_tensor.unsqueeze(0).to(device)\n",
    "        \n",
    "        # Make prediction with AMP (if enabled)\n",
    "        with autocast(device_type='cuda', dtype=amp_dtype):\n",
    "            prediction_mask_logits = model(img_batch)\n",
    "        \n",
    "        # Convert logits to probabilities and threshold\n",
    "        # Convert to float32 before numpy conversion (bfloat16/float16 not supported by numpy)\n",
    "        prediction_mask_probs = torch.sigmoid(prediction_mask_logits).float()\n",
    "        prediction_mask = (prediction_mask_probs.squeeze().cpu().numpy() > 0.5).astype(np.uint8)\n",
    "        \n",
    "        # Convert tensors to numpy for visualization\n",
    "        img_np = img_tensor.permute(1, 2, 0).cpu().numpy()  # (C, H, W) -> (H, W, C)\n",
    "        mask_np = mask_tensor.squeeze().cpu().numpy()  # (1, H, W) -> (H, W)\n",
    "        \n",
    "        # Denormalize image for correct display (reverse ImageNet normalization)\n",
    "        img_np = denormalize_imagenet(img_np)\n",
    "        \n",
    "        test_images.append(img_np)\n",
    "        test_masks.append(mask_np)\n",
    "        test_predictions.append(prediction_mask)\n",
    "\n",
    "# Visualize results in a grid (5 rows x 4 columns for 20 images)\n",
    "# Each row shows: Original, GT Mask, Predicted Mask, Overlay\n",
    "fig, axes = plt.subplots(num_test_images, 4, figsize=(16, 4 * num_test_images))\n",
    "\n",
    "for i in range(num_test_images):\n",
    "    # Original image (already denormalized)\n",
    "    axes[i, 0].imshow(test_images[i])\n",
    "    axes[i, 0].set_title(f'Original Image {i+1}')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Ground truth mask\n",
    "    axes[i, 1].imshow(test_masks[i], cmap='gray')\n",
    "    axes[i, 1].set_title('Ground Truth Mask')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Predicted mask\n",
    "    axes[i, 2].imshow(test_predictions[i], cmap='gray')\n",
    "    axes[i, 2].set_title('Predicted Mask')\n",
    "    axes[i, 2].axis('off')\n",
    "    \n",
    "    # Overlay: original image with predicted mask in red\n",
    "    overlay = test_images[i].copy()  # Already denormalized\n",
    "    mask_colored = np.zeros_like(overlay)\n",
    "    mask_colored[:, :, 0] = test_predictions[i]  # Red channel\n",
    "    overlay = np.clip(overlay * 0.6 + mask_colored * 0.4, 0, 1)\n",
    "    axes[i, 3].imshow(overlay)\n",
    "    axes[i, 3].set_title('Overlay (Original + Prediction)')\n",
    "    axes[i, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "total_mask_pixels = sum(pred.sum() for pred in test_predictions)\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  Total test images: {num_test_images}\")\n",
    "print(f\"  Total predicted mask pixels: {total_mask_pixels}\")\n",
    "print(f\"  Average mask pixels per image: {total_mask_pixels / num_test_images:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1751822593057,
     "user": {
      "displayName": "JAYESH SHARMA",
      "userId": "10181368842352240411"
     },
     "user_tz": -330
    },
    "id": "6m00txLwwvLK",
    "outputId": "a0be7697-3058-4721-9fa5-f94bc859023a"
   },
   "outputs": [],
   "source": [
    "# Save the complete model (architecture + weights + optimizer state)\n",
    "# Method 1: Save only state dict (recommended - smaller file, requires model definition to load)\n",
    "complete_state_path = os.path.join(config.CHECKPOINT_DIR, config.MODEL_COMPLETE_NAME)\n",
    "torch.save(model.state_dict(), complete_state_path)\n",
    "\n",
    "# Method 2: Save entire model (larger file, but can load without model definition)\n",
    "complete_checkpoint_path = os.path.join(config.CHECKPOINT_DIR, config.MODEL_COMPLETE_NAME.replace('.pth', '.pt'))\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': len(history['train_loss']),\n",
    "    'val_loss': best_val_loss,\n",
    "    'model_config': {\n",
    "        'in_channels': config.IN_CHANNELS, \n",
    "        'out_channels': config.OUT_CHANNELS,\n",
    "        'r': config.CBAM_REDUCTION\n",
    "    }\n",
    "}, complete_checkpoint_path)\n",
    "\n",
    "print(\"Model saved in PyTorch formats:\")\n",
    "print(f\"1. State dict only: {complete_state_path}\")\n",
    "print(f\"2. Complete checkpoint: {complete_checkpoint_path}\")\n",
    "print(\"\\nTo load the model later:\")\n",
    "print(\"  # For state dict:\")\n",
    "print(f\"  model = MaxViT_CBAM_UNet(in_channels={config.IN_CHANNELS}, out_channels={config.OUT_CHANNELS}, r={config.CBAM_REDUCTION}).to(device)\")\n",
    "print(f\"  model.load_state_dict(torch.load('{complete_state_path}'))\")\n",
    "print(\"\\n  # For complete checkpoint:\")\n",
    "print(f\"  checkpoint = torch.load('{complete_checkpoint_path}')\")\n",
    "print(\"  model.load_state_dict(checkpoint['model_state_dict'])\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN/3bJq0t7seGZVjQAMTzsd",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
