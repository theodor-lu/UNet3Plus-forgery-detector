{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3S2pWCJXQgV4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, SubsetRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from time import time\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IQnefHMnQgWK"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(4460);\n",
    "np.random.seed(4460)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qAJl34pVQgWL",
    "outputId": "3c74eebb-6c8f-486e-d6c8-534c5b2e30a4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, cuda, device, optim\n",
    "print('currentdevice=',torch.cuda.current_device())\n",
    "print('totaldevice=',torch.cuda.device_count())\n",
    "print('changedevice=',torch.cuda.device(1))\n",
    "print('availabledevice=',torch.cuda.is_available())\n",
    "\n",
    "device = device('cuda:0')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jF6in2YbQgWN"
   },
   "outputs": [],
   "source": [
    "# Dataset folder used\n",
    "DATASET_PATH = os.path.join('./AATTCT-IDS/Image/Extracted/')\n",
    "\n",
    "# We would like to perform a train-validation-test split at the ratio of T:V:T = 6:2:2.\n",
    "VAL_SPLIT = 0.3\n",
    "TEST_SPLIT = 0.1\n",
    "img_size = size=256\n",
    "# Batch size for training. Limited by GPU memory\n",
    "BATCH_SIZE = 2\n",
    "# Training Epochs\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=4):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "                nn.Linear(channel, channel // reduction),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(channel // reduction, channel),        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        y = torch.clamp(y, 0, 1)\n",
    "        return x * y\n",
    "\n",
    "def depthwise_conv(inp, oup, kernel_size=3, stride=1, relu=False):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, kernel_size, stride, kernel_size//2, groups=inp, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU(inplace=True) if relu else nn.Sequential(),\n",
    "    )\n",
    "\n",
    "class GhostModule(nn.Module):\n",
    "    def __init__(self, inp, oup, kernel_size=1, ratio=2, dw_size=3, stride=1, relu=True):\n",
    "        super(GhostModule, self).__init__()\n",
    "        self.oup = oup\n",
    "        init_channels = math.ceil(oup / ratio)\n",
    "        new_channels = init_channels*(ratio-1)\n",
    "\n",
    "        self.primary_conv = nn.Sequential(\n",
    "            nn.Conv2d(inp, init_channels, kernel_size, stride, kernel_size//2, bias=False),\n",
    "            nn.BatchNorm2d(init_channels),\n",
    "            nn.ReLU(inplace=True) if relu else nn.Sequential(),\n",
    "        )\n",
    "\n",
    "        self.cheap_operation = nn.Sequential(\n",
    "            nn.Conv2d(init_channels, new_channels, dw_size, 1, dw_size//2, groups=init_channels, bias=False),\n",
    "            nn.BatchNorm2d(new_channels),\n",
    "            nn.ReLU(inplace=True) if relu else nn.Sequential(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.primary_conv(x)\n",
    "        x2 = self.cheap_operation(x1)\n",
    "        out = torch.cat([x1,x2], dim=1)\n",
    "        return out[:,:self.oup,:,:]\n",
    "\n",
    "\n",
    "class GhostBottleneck(nn.Module):\n",
    "    def __init__(self, inp, hidden_dim, oup, kernel_size, stride):\n",
    "        super(GhostBottleneck, self).__init__()\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            # pw\n",
    "            GhostModule(inp, hidden_dim, kernel_size=1, relu=True),\n",
    "            # dw\n",
    "            depthwise_conv(hidden_dim, hidden_dim, kernel_size, stride, relu=False) if stride==2 else nn.Sequential(),\n",
    "            # Squeeze-and-Excite\n",
    "            SELayer(hidden_dim),\n",
    "            # pw-linear\n",
    "            GhostModule(hidden_dim, oup, kernel_size=1, relu=False),\n",
    "        )\n",
    "\n",
    "        if stride == 1 and inp == oup:\n",
    "            self.shortcut = nn.Sequential()\n",
    "        else:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                depthwise_conv(inp, inp, kernel_size, stride, relu=False),\n",
    "                nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x) + self.shortcut(x)\n",
    "\n",
    "#Nested Unet\n",
    "\n",
    "class Ghost_Unet(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of this paper:\n",
    "    https://arxiv.org/pdf/1807.10165.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch=1, out_ch=1):\n",
    "        super(Ghost_Unet, self).__init__()\n",
    "\n",
    "        n1 = 16\n",
    "        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.GBneck0_0 = GhostBottleneck(in_ch, filters[0], filters[0],3,1)\n",
    "        self.GBneck1_0 = GhostBottleneck(filters[0], filters[1], filters[1],3,1)\n",
    "        self.GBneck2_0 = GhostBottleneck(filters[1], filters[2], filters[2],3,1)\n",
    "        self.GBneck3_0 = GhostBottleneck(filters[2], filters[3], filters[3],3,1)\n",
    "        self.GBneck4_0 = GhostBottleneck(filters[3], filters[4],filters[4],3,1)\n",
    "\n",
    "        self.GBneck0_1 = GhostBottleneck(filters[0] + filters[1], filters[0], filters[0],3,1)\n",
    "        self.GBneck1_1 = GhostBottleneck(filters[1] + filters[2], filters[1], filters[1],3,1)\n",
    "        self.GBneck2_1 = GhostBottleneck(filters[2] + filters[3], filters[2], filters[2],3,1)\n",
    "        self.GBneck3_1 = GhostBottleneck(filters[3] + filters[4], filters[3], filters[3],3,1)\n",
    "\n",
    "        self.GBneck0_2 = GhostBottleneck(filters[0]*2 + filters[1], filters[0], filters[0],3,1)\n",
    "        self.GBneck1_2 = GhostBottleneck(filters[1]*2 + filters[2], filters[1], filters[1],3,1)\n",
    "        self.GBneck2_2 = GhostBottleneck(filters[2]*2 + filters[3], filters[2], filters[2],3,1)\n",
    "\n",
    "        self.GBneck0_3 = GhostBottleneck(filters[0]*3 + filters[1], filters[0], filters[0],3,1)\n",
    "        self.GBneck1_3 = GhostBottleneck(filters[1]*3 + filters[2], filters[1], filters[1],3,1)\n",
    "\n",
    "        self.GBneck0_4 = GhostBottleneck(filters[0]*4 + filters[1], filters[0], filters[0],3,1)\n",
    "\n",
    "        self.final = nn.Conv2d(filters[0], out_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x0_0 = self.GBneck0_0(x)\n",
    "        x1_0 = self.GBneck1_0(self.pool(x0_0))\n",
    "        x0_1 = self.GBneck0_1(torch.cat([x0_0, self.Up(x1_0)], 1))\n",
    "\n",
    "        x2_0 = self.GBneck2_0(self.pool(x1_0))\n",
    "        x1_1 = self.GBneck1_1(torch.cat([x1_0, self.Up(x2_0)], 1))\n",
    "        x0_2 = self.GBneck0_2(torch.cat([x0_0, x0_1, self.Up(x1_1)], 1))\n",
    "\n",
    "        x3_0 = self.GBneck3_0(self.pool(x2_0))\n",
    "        x2_1 = self.GBneck2_1(torch.cat([x2_0, self.Up(x3_0)], 1))\n",
    "        x1_2 = self.GBneck1_2(torch.cat([x1_0, x1_1, self.Up(x2_1)], 1))\n",
    "        x0_3 = self.GBneck0_3(torch.cat([x0_0, x0_1, x0_2, self.Up(x1_2)], 1))\n",
    "\n",
    "        x4_0 = self.GBneck4_0(self.pool(x3_0))\n",
    "        x3_1 = self.GBneck3_1(torch.cat([x3_0, self.Up(x4_0)], 1))\n",
    "        x2_2 = self.GBneck2_2(torch.cat([x2_0, x2_1, self.Up(x3_1)], 1))\n",
    "        x1_3 = self.GBneck1_3(torch.cat([x1_0, x1_1, x1_2, self.Up(x2_2)], 1))\n",
    "        x0_4 = self.GBneck0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.Up(x1_3)], 1))\n",
    "\n",
    "        output = self.final(x0_4)\n",
    "        output = F.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMHjJrzDQgWY"
   },
   "outputs": [],
   "source": [
    "def dice_coefficient(predicted, target):\n",
    "   \n",
    "        #     Returns:\n",
    "    #         coefficient(float): Dice coefficient for the input sample.\n",
    "        #                                     1 represents highest similarity and\n",
    "\n",
    "    # The smooth term is used to prevent division by zero.\n",
    "    smooth = 1\n",
    "    product = np.multiply(predicted, target)\n",
    "    intersection = np.sum(product)\n",
    "    coefficient = (2 * intersection + smooth) / (np.sum(predicted) + np.sum(target) + smooth)\n",
    "    return coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0IYCiwB6QgWZ",
    "outputId": "0c618a1e-c400-42de-a7d4-bd1f1b89aab1"
   },
   "outputs": [],
   "source": [
    "unet_model = None\n",
    "unet_classifier = None\n",
    "#criterion = nn.BCELoss()\n",
    "learning_rate = 0.0001\n",
    "\n",
    "#### If you want to see the training trend within each epoch, you can change mini_batch to a positive integer \n",
    "#### that is no larger than the number of batches per epoch.\n",
    "mini_batch = False\n",
    "#FILTER_LIST = [16,32,64,128,256]\n",
    "# Define where to save the model parameters.\n",
    "model_save_path = './saved_models/'\n",
    "os.makedirs(model_save_path, exist_ok = True)\n",
    "\n",
    "# New model is created.\n",
    "unet_model = Ghost_Unet().to(device)\n",
    "\n",
    "#### You can uncomment this to see the textual architecture of our U-Net.\n",
    "print(unet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N9oBt9IBQgWZ"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XYbZHisMQgWa"
   },
   "outputs": [],
   "source": [
    "def dice_loss(inputs, targets):\n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        #inputs = F.sigmoid(inputs)       \n",
    "        smooth=1\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_score(output, target, smooth=1e-6):\n",
    "    output = torch.sigmoid(output)\n",
    "    output = (output > 0.5).float()\n",
    "    intersection = (output * target).sum()\n",
    "    union = output.sum() + target.sum() - intersection\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "k_folds = 10\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(unet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Validation_Data=(train_indices+validation_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start=time()\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm  # For progress bar\n",
    "# Define the paths for images and masks\n",
    "image_dir = './AATTCT-IDS/Image/Extracted/'\n",
    "mask_dir = './AATTCT-IDS/Label/Visceral/'\n",
    "\n",
    "# Initialize the dataset with the correct arguments\n",
    "custom_dataset = CustomDataset(image_dir=image_dir, mask_dir=mask_dir, img_size=256)\n",
    "for fold,(train_idx,val_idx) in enumerate(kfold.split(Training_Validation_Data)):\n",
    "    \n",
    "    print('------------fold no---------{}----------------------'.format(fold))\n",
    "    # Get indices for train, validation, and test split\n",
    "    train_indices, val_indices, test_indices = get_indices(len(custom_dataset), val_split=VAL_SPLIT, test_split=TEST_SPLIT)\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(val_indices)\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(custom_dataset, batch_size=BATCH_SIZE, sampler=train_sampler, shuffle=False)\n",
    "    val_loader = DataLoader(custom_dataset, batch_size=1, sampler=val_sampler, shuffle=False)\n",
    "\n",
    "    #train_sampler, validation_sampler = SubsetRandomSampler(train_idx), SubsetRandomSampler(test_idx)\n",
    "    #trainloader = torch.utils.data.DataLoader(CustomDataset(DATASET_PATH), BATCH_SIZE, sampler = train_idx)\n",
    "    #validationloader = torch.utils.data.DataLoader(CustomDataset(DATASET_PATH), 1, sampler = val_idx)\n",
    "    \n",
    "        # Training session history data.\n",
    "    history = {'train_loss': list(), 'validation_loss': list(), 'train_score': list(), 'validation_score': list()}\n",
    "\n",
    "    # For save best feature. Initial loss taken a very high value.\n",
    "    last_score = 0\n",
    "\n",
    "    # Optimizer used for training process. Adam Optimizer.\n",
    "    optimizer = optim.Adam(unet_model.parameters(), lr = learning_rate)\n",
    "    # Reducing LR on plateau feature to improve training.\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.85, patience = 2, verbose = True)\n",
    "    early_stopping = EarlyStopping(patience=15, verbose=True)\n",
    "    print('Starting Training Process')\n",
    "\n",
    "    assert validationloader.batch_size == 1\n",
    "\n",
    "    # Epoch Loop\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        #################################### Train ####################################################\n",
    "        unet_model.train()\n",
    "        start_time = time()\n",
    "        # Training a single epoch\n",
    "        train_epoch_loss, train_batch_loss, batch_iteration = 0, 0, 0\n",
    "        validation_score, validation_loss = 0, 0\n",
    "        Training_score=0\n",
    "        Training_iou_score = 0\n",
    "        for batch, data in enumerate(trainloader):\n",
    "            # Keeping track how many iteration is happening.\n",
    "            batch_iteration += 1\n",
    "            # Loading data to device used.\n",
    "            image = data['image'].to(device)\n",
    "            mask = data['mask'].to(device)\n",
    "            # Clearing gradients of optimizer.\n",
    "            optimizer.zero_grad()\n",
    "            # Calculation predicted output using forward pass.\n",
    "            output = unet_model(image)\n",
    "            # Calculating the loss value.\n",
    "            loss_value = dice_loss(output, mask)\n",
    "            # Computing the gradients.\n",
    "            loss_value.backward()\n",
    "            # Optimizing the network parameters.\n",
    "            optimizer.step()\n",
    "            # Updating the running training loss\n",
    "            train_epoch_loss += loss_value.item()\n",
    "            train_batch_loss += loss_value.item()\n",
    "\n",
    "            # Threshold elimination.\n",
    "            output = (output > 0.5)\n",
    "            output = output.cpu().numpy()\n",
    "            mask = mask.cpu().numpy()\n",
    "            mask = np.resize(mask, (1, size, size))\n",
    "            output = np.resize(output, (1, size, size))\n",
    "            # Calculate the dice score for original and predicted image mask.\n",
    "            Training_score += dice_coefficient(output, mask)\n",
    "            # Calculate the IoU score for original and predicted image mask.\n",
    "            Training_iou_score += iou_score(torch.tensor(output), torch.tensor(mask))\n",
    "\n",
    "            # Printing batch logs if any. Useful if you want to see the training trends within each epoch.\n",
    "            if mini_batch:\n",
    "                if (batch + 1) % mini_batch == 0:\n",
    "                    train_batch_loss = train_batch_loss / (mini_batch * trainloader.batch_size)\n",
    "                    print(\n",
    "                        f'    Batch: {batch + 1:2d},\tBatch Loss: {train_batch_loss:.7f}')\n",
    "                    train_batch_loss = 0\n",
    "\n",
    "        train_epoch_loss = train_epoch_loss / (batch_iteration * trainloader.batch_size)\n",
    "        unet_train = Training_score / batch_iteration\n",
    "        unet_train_iou = Training_iou_score / batch_iteration\n",
    "        ################################### Validation ##################################################\n",
    "        unet_model.eval()\n",
    "        # To get data in loops.\n",
    "        batch_iteration = 0\n",
    "\n",
    "        validation_iou_score = 0\n",
    "        for batch, data in enumerate(validationloader):\n",
    "            # Keeping track how many iteration is happening.\n",
    "            batch_iteration += 1\n",
    "            # Data prepared to be given as input to model.\n",
    "            image = data['image'].to(device)\n",
    "            mask = data['mask'].to(device)\n",
    "           # Predicted output from the input sample.\n",
    "            mask_prediction = unet_model(image)\n",
    "\n",
    "            # comput validation loss\n",
    "            loss_value = dice_loss(mask_prediction, mask)\n",
    "            validation_loss += loss_value.item()\n",
    "\n",
    "            # Threshold elimination.\n",
    "            mask_prediction = (mask_prediction > 0.5)\n",
    "            mask_prediction = mask_prediction.cpu().numpy()\n",
    "            mask = mask.cpu().numpy()\n",
    "\n",
    "            mask = np.resize(mask, (1, size, size))\n",
    "            mask_prediction = np.resize(mask_prediction, (1, size, size))\n",
    "            # Calculate the dice score for original and predicted image mask.\n",
    "            validation_score += dice_coefficient(mask_prediction, mask)\n",
    "            # Calculate the IoU score for original and predicted image mask.\n",
    "            validation_iou_score += iou_score(torch.tensor(mask_prediction), torch.tensor(mask))\n",
    "\n",
    "        # Calculating the mean score for the whole validation dataset.\n",
    "        unet_val = validation_score / batch_iteration\n",
    "        unet_val_iou = validation_iou_score / batch_iteration\n",
    "        validation_loss = validation_loss / batch_iteration\n",
    "\n",
    "        # Collecting all epoch loss mse = mean_squared_error(predicted, target)\n",
    "        history['train_loss'].append(train_epoch_loss)\n",
    "        history['validation_loss'].append(validation_loss)\n",
    "\n",
    "        # Collecting all epoch score values for future visualization.\n",
    "        history['train_score'].append(unet_train)\n",
    "        history['validation_score'].append(unet_val)\n",
    "\n",
    "        # Reduce LR On Plateau\n",
    "        scheduler.step(validation_loss)\n",
    "\n",
    "        time_taken = time() - start_time\n",
    "\n",
    "        # Training Logs printed.\n",
    "        print(f'Epoch: {epoch + 1:3d},  ', end = '')\n",
    "        print(f'train Loss: {train_epoch_loss:.5f},  ', end = '')\n",
    "        print(f'Training score (Dice): {unet_train:.5f},  ', end = '')\n",
    "        print(f'Training score (IoU): {unet_train_iou:.5f},  ', end = '')\n",
    "        print(f'validation Loss: {validation_loss:.5f},  ', end = '')\n",
    "        print(f'validation score (Dice): {unet_val:.5f},  ', end = '')\n",
    "        print(f'validation score (IoU): {unet_val_iou:.5f},  ', end = '')\n",
    "\n",
    "        for pg in optimizer.param_groups:\n",
    "            print('current lr: ', pg['lr'], ', ', end = '')\n",
    "        print(f'Time: {time_taken:.2f} s', end = '')\n",
    "\n",
    "        early_stopping(validation_loss, unet_model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        # Save the model every epoch.\n",
    "        current_epoch_model_save_path = os.path.join(model_save_path, 'GhostUnet_Scapis_Abdomen_VAT_epoch_%s.pth' % (str(epoch).zfill(3)))\n",
    "        torch.save(unet_model.state_dict(), current_epoch_model_save_path)\n",
    "\n",
    "        # Save the best model (determined by validation score) and give it a unique name.\n",
    "        best_model_path = os.path.join(model_save_path, 'GhostUnet_Scapis_Abdomen_VAT_best_model.pth')\n",
    "        if  last_score < unet_val:\n",
    "            torch.save(unet_model.state_dict(), best_model_path)\n",
    "            last_score = unet_val\n",
    "            print(f'\tBest model saved at score: {unet_val:.5f}')\n",
    "        else:\n",
    "            print()\n",
    "\n",
    "    print(f'Training Finished after {epochs} epoches')\n",
    "    \n",
    "# end = time.time ()\n",
    "# time spent = (end-start) /60\n",
    "# print (f\" (time spent: .3} minutes\") \n",
    "print(f'Time: {time() - start}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.grid(color='r', linestyle='dotted', linewidth=0.5)\n",
    "plt.plot(history['train_loss'], 'o-', color = '#9900CC')\n",
    "plt.plot(history['validation_loss'], 'o-', color = '#00cc33')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.grid(color='r', linestyle='dotted', linewidth=0.5)\n",
    "plt.plot(history['train_score'], 'o-', color = '#9900CC')\n",
    "plt.plot(history['validation_score'], 'o-', color = '#00cc33')\n",
    "plt.title('model score')\n",
    "plt.ylabel('Dice score')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wgfR83NoQgWd",
    "outputId": "2ba9f034-de41-42fc-cc94-d70b616b6ff2"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start=time()\n",
    "# Load the unet model at its prime (when it performed the best on the validation set).\n",
    "state_dict = torch.load(os.path.join(model_save_path, 'GhostUnet_Scapis_Abdomen_VAT_best_model.pth'))\n",
    "unet_model.load_state_dict(state_dict)\n",
    "\n",
    "# Testing process on test data.\n",
    "unet_model.eval()\n",
    "# Getting test data indices for dataloading\n",
    "test_data_indexes = test_indices\n",
    "# Total testing data used.\n",
    "data_length = len(test_data_indexes)\n",
    "# Score after testing on dataset.\n",
    "mean_test_dice_score = 0\n",
    "mean_test_iou_score = 0\n",
    "\n",
    "for batch, data in enumerate(testloader):\n",
    "    # Data prepared to be given as input to model.\n",
    "    image = data['image'].to(device)\n",
    "    mask = data['mask']\n",
    "\n",
    "    # Predicted output from the input sample.\n",
    "    mask_prediction = unet_model(image).cpu()\n",
    "    # Threshold elimination.\n",
    "    mask_prediction = (mask_prediction > 0.5)\n",
    "    mask_prediction = mask_prediction.numpy()\n",
    "\n",
    "    mask = np.resize(mask, (1, img_size, img_size))\n",
    "    mask_prediction = np.resize(mask_prediction, (1, img_size, img_size))\n",
    "\n",
    "    # Calculating the dice score for original and predicted mask.\n",
    "    mean_test_dice_score += dice_coefficient(mask_prediction, mask)\n",
    "    # Calculating the IoU score for original and predicted mask.\n",
    "    mean_test_iou_score += iou_score(torch.tensor(mask_prediction), torch.tensor(mask))\n",
    "\n",
    "# Calculating the mean scores for the whole test dataset.\n",
    "unet_dice_score = mean_test_dice_score / data_length\n",
    "unet_iou_score = mean_test_iou_score / data_length\n",
    "# Putting the model back to training mode.\n",
    "print(f'\\nDice Score {unet_dice_score}\\n')\n",
    "print(f'IoU Score {unet_iou_score}\\n')\n",
    "\n",
    "print(f'Time: {time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import segmentation\n",
    "#result_image = segmentation.mark_boundaries(input_image, segmentation_results, mode='thick')\n",
    "from scipy import ndimage\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZCDf0m2nQgWe"
   },
   "outputs": [],
   "source": [
    "def result(image, mask, output, title, transparency = 0.02, save_path = None):\n",
    "    '''\n",
    "    Plots a 2x3 plot with comparisons of output and original image.\n",
    "    Works best with Jupyter Notebook/Lab.\n",
    "    Parameters:\n",
    "        image(numpy.ndarray): Array containing the ofrom skimage import segmentation\n",
    "#result_image = segmentation.mark_boundaries(input_image, segmentation_results, mode='thick')\n",
    "\n",
    "from scipy import ndimageriginal image of MRI scan.\n",
    "        mask(numpy.ndarray): Array containing the original mask of tumor.\n",
    "        output(numpy.ndarray): Model predicted mask from input image.\n",
    "        title(str): Title of the plot to be used.\n",
    "        transparency(float): Transparency level of mask on images.\n",
    "                             Default: 0.38\n",
    "        save_path(str): Saves the plot to the location specified.\n",
    "                        Does nothing if None. \n",
    "                        Default: None\n",
    "    Return:\n",
    "        None\n",
    "    '''\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, sharex=True, sharey=True, figsize=(\n",
    "        20, 15), gridspec_kw={'wspace': 0.025, 'hspace': 0.010})\n",
    "    fig.suptitle(title, x=0.5, y=0.92, fontsize=20)\n",
    "\n",
    "    axs[0][0].set_title(\"Original Mask\", fontdict={'fontsize': 16})\n",
    "    axs[0][0].imshow(mask, cmap='gray')\n",
    "    axs[0][0].set_axis_off()\n",
    "\n",
    "    axs[0][1].set_title(\"Predicted Mask\", fontdict={'fontsize': 16})\n",
    "    axs[0][1].imshow(output, cmap='gray')\n",
    "    axs[0][1].set_axis_off()\n",
    "\n",
    "    mask_diff = np.abs(np.subtract(mask, output))\n",
    "    axs[0][2].set_title(\"Mask Difference\", fontdict={'fontsize': 16})\n",
    "    axs[0][2].imshow(mask_diff, cmap='gray')\n",
    "    axs[0][2].set_axis_off()\n",
    "\n",
    "    seg_output = mask*transparency\n",
    "    seg_image = np.add(image, seg_output)/2\n",
    "    axs[1][0].set_title(\"Original Segmentation\", fontdict={'fontsize': 16})\n",
    "    axs[1][0].imshow(seg_image, cmap='gray')\n",
    "    axs[1][0].set_axis_off()\n",
    "\n",
    "    seg_output = output*transparency\n",
    "\n",
    "    labeled_seg_output, _ = ndimage.label(seg_output)\n",
    "    #result_image = segmentation.mark_boundaries(image, labeled_seg_output, mode='thick')\n",
    "    seg_image = np.add(image, labeled_seg_output)/2\n",
    "    result_image = segmentation.mark_boundaries(seg_image, output,color=(1, 1, 0), mode='thick')\n",
    "    \n",
    "    axs[1][1].set_title(\"Predicted Segmentation\", fontdict={'fontsize': 16})\n",
    "    axs[1][1].imshow(result_image, cmap='gray')\n",
    "    axs[1][1].set_axis_off()\n",
    "\n",
    "    axs[1][2].set_title(\"Original Input Image\", fontdict={'fontsize': 16})\n",
    "    axs[1][2].imshow(image, cmap='gray')\n",
    "    axs[1][2].set_axis_off()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi = 90, bbox_inches = 'tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AbVN31uhQgWe",
    "outputId": "74304ef1-7a54-46ea-8691-2040d225beab"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "start=time()\n",
    "for example_index in range(10):\n",
    "    # The purpose of image_index is to make sure we truly pick from the test set.\n",
    "    \n",
    "    image_index = test_indices[example_index]\n",
    "    sample = custom_dataset[image_index]\n",
    "    threshold = 0.5\n",
    "\n",
    "    unet_model.eval()\n",
    "    image = sample['image'].numpy()\n",
    "    mask = sample['mask'].numpy()\n",
    "\n",
    "    image_tensor = torch.Tensor(image)\n",
    "    image_tensor = image_tensor.view((-1, 1, img_size, img_size)).to(device)\n",
    "    output = unet_model(image_tensor).detach().cpu()\n",
    "    output = (output > threshold)\n",
    "    output = output.numpy()\n",
    "\n",
    "    # image(numpy.ndarray): 512x512 Original brain scanned image.\n",
    "    image = np.resize(image, (img_size, img_size))\n",
    "    # mask(numpy.ndarray): 512x512 Original mask of scanned image.\n",
    "    mask = np.resize(mask, (img_size, img_size))\n",
    "    # output(numpy.ndarray): 512x512 Generated mask of scanned image.                                            \n",
    "    output = np.resize(output, (img_size, img_size))\n",
    "    # score(float): Sørensen–Dice Coefficient for mask and output. Calculates how similar are the two images.\n",
    "    d_score = dice_coefficient(output, mask)\n",
    "    # score(float): IoU for mask and output.\n",
    "    iou = iou_score(torch.tensor(output), torch.tensor(mask))\n",
    "\n",
    "    title = f'Name: {image_index}.png   Dice Score: {d_score:.5f}   IoU Score: {iou:.5f}'\n",
    "    save_path = os.path.join('./output_ghostnet/',f'{d_score:.5f}_{image_index}.png')\n",
    "    result(image, mask, output, title, save_path = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LiverTumorSegmentation_Code_Unet__.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
